---
format:
  revealjs:
    theme: [default, custom.scss]
    logo: "../images/metrics_hex.png"
    footer: "[ECON 480 — Econometrics](https://metricsF22.classes.ryansafner.com)"
    height: 900
    width: 1600
    #df-print: paged
    slide-number: c
    chalkboard: true
overview: true
execute:
  echo: false
  warning: false
  freeze: auto
---

##  {data-menu-title="Title Slide" background-image="images/metrics_title_slide.png"}

[2.1 --- Data 101 & Descriptive Stats]{.custom-title}

[ECON 4470 • Econometrics]{.custom-subtitle}

[Jordan Izenwasser <br> Slides Adapated from Ryan Safner, PhD]{.custom-author}



```{r}
#| label: setup
#| include: false
library(tidyverse)
library(kableExtra)
library(patchwork)
library(fontawesome)
library(gapminder)
library(ggthemes)
library(scales)
knitr::opts_chunk$set(echo=F,
                      message=F,
                      warning=F)
update_geom_defaults("label", list(family = "Fira Sans Condensed"))
update_geom_defaults("text", list(family = "Fira Sans Condensed"))

```

## Contents {background-color="#314f4f"}

[The Two Big Problems with Data](#the-two-big-problems-with-data)

[Data 101](#data-101)

[Descriptive Statistics](#descriptive-statistics)

[Measures of Center](#measures-of-center)

[Measures of Dispersion](#measures-of-dispersion)


# The Two Big Problems with Data {background-color="#314f4f" .centered}

## Two Big Problems with Data

::: columns
::: {.column width="50%"}
- We want to use econometrics to [identify]{.hi} causal relationships and make [inferences]{.hi} about them

1. Problem for [identification]{.hi}: [endogeneity]{.hi-purple}

2. Problem for [inference]{.hi}: [randomness]{.hi-purple}

:::

::: {.column width="50%"}

![](images/randomimage.jpg){width="750" fig-align="center"}
:::
:::

## Identification Problem: Endogeneity

::: columns
::: {.column width="50%"}
- An independent variable $(X)$ is [exogenous]{.hi-purple} if its variation is [unrelated]{.hi-turquoise} to other factors that affect the dependent variable $(Y)$

- An independent variable $(X)$ is [endogenous]{.hi-purple} if its variation is [related]{.hi-turquoise} to other factors that affect the dependent variable $(Y)$

- Note: unfortunately this is different from how economists talk about “endogenous” vs. “exogenous” variables in theoretical models...

:::

::: {.column width="50%"}

![](images/causality.jpg){width="750" fig-align="center"}
:::
:::

## Identification Problem: Endogeneity

::: columns
::: {.column width="50%"}
- An independent variable $(X)$ is [exogenous]{.hi-purple} if its variation is [unrelated]{.hi-turquoise} to other factors that affect the dependent variable $(Y)$


:::

::: {.column width="50%"}

```{r}
#| fig-height: 10
library(ggdag)
library(patchwork)

h1 <- dagify(Y ~ X,
             exposure = "X",
             outcome = "Y",
             coords = list(
               x = c(X = 1,Y = 2),
               y = c(X = 1,Y = 1)
               )) %>% 
  tidy_dagitty() %>%
  node_status() %>%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges()+
  geom_dag_point(aes(color = status), size = 15)+
  geom_dag_text()+ 
  guides(color = F)+
  labs(title = "X causes Y")+
  theme_dag(base_family = "Fira Sans Condensed")

h2 <- dagify(Y ~ X + Z,
             exposure = "X",
             outcome = "Y",
             coords=list(
               x=c(Z=1,X=1,Y=2),
               y=c(Z=2,X=1,Y=1.5)
             )) %>% 
  tidy_dagitty() %>%
  node_status() %>%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges()+
  geom_dag_point(aes(color = status), size = 15)+
  geom_dag_text()+ 
  guides(color = F)+
  coord_cartesian(ylim = c(-0.75,2.25))+
  labs(title = "X and Z (independently) cause Y")+
  theme_dag(base_family = "Fira Sans Condensed")

h1  / h2
```
:::
:::

## Identification Problem: Endogeneity

::: columns
::: {.column width="50%"}
- An independent variable $(X)$ is [endogenous]{.hi-purple} if its variation is [related]{.hi-turquoise} to other factors that affect the dependent variable $(Y)$, e.g. $Z$


:::

::: {.column width="50%"}

```{r}
#| fig-height: 10

h3 <- dagify(Y ~ X + Z,
             X ~ Z,
             exposure = "X",
             outcome = "Y",
             coords = list(
               x=c(X=1, Z=1.5, Y=2),
               y=c(X=1, Z=2, Y=1)
               )) %>% 
  tidy_dagitty() %>%
  node_status() %>%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges()+
  geom_dag_point(aes(color = status), size = 15)+
  geom_dag_text()+ 
  guides(color = F)+
  #coord_cartesian(ylim = c(-0.75, 2.75))+
  labs(title = "Z causes X and Y")+
  theme_dag(base_family = "Fira Sans Condensed")

h4 <- dagify(Y ~ Z,
             Z ~ X,
             exposure = "X",
             outcome = "Y",
             coords=list(
               x=c(X=1, Z=1.5, Y=2),
               y=c(X=1, Z=1, Y=1)
             )) %>% 
  tidy_dagitty() %>%
  node_status() %>%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges()+
  geom_dag_point(aes(color = status), size = 15)+
  geom_dag_text()+ 
  guides(color = F)+
  #coord_cartesian(ylim = c(-0.75, 2.75))+
  labs(title = "X Causes Y Indirectly Through Z")+
  theme_dag(base_family = "Fira Sans Condensed")

h5 <- dagify(Y ~ X + Z,
              Z ~ X,
             exposure = "X",
             outcome = "Y",
             coords=list(
               x=c(X=1, Z=1.5, Y=2),
               y=c(X=1, Z=0.5, Y=1)
             )) %>% 
  tidy_dagitty() %>%
  node_status() %>%
  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_edges()+
  geom_dag_point(aes(color = status), size = 15)+
  geom_dag_text()+ 
  guides(color = F)+
  #coord_cartesian(ylim = c(-1, 2.75))+
  labs(title = "X Causes Y Directly and Through Z")+
  theme_dag(base_family = "Fira Sans Condensed")

h3  / h4 / h5
```
:::
:::


## Inference Problem: Randomness

::: columns
::: {.column width="50%"}
- Data is [random]{.hi-purple} due to [natural sampling variation]{.hi-purple}
  - Taking one sample of a population will yield slightly different information than another sample of the same population 
- Common in statistics, *easy to fix*

- [Inferential Statistics]{.hi}: making claims about a wider population using sample data 
  - We use common tools and techniques to deal with randomness

:::

::: {.column width="50%"}
![](images/sampling.jpg){width="750" fig-align="center"}
:::

:::

## The Two Problems: Where We're Heading...Ultimately

[[Sample]{.b} $\color{#6A5ACD}{\xrightarrow{\text{statistical inference}}}$ [Population]{.b} $\color{#e64173}{\xrightarrow{\text{causal indentification}}}$ [Unobserved Parameters]{.b}]{.center}

<br>

. . .

- We want to [identify]{.hi} causal relationships between **population** variables
  - Logically first thing to consider
  - [Endogeneity problem]{.hi-purple}

. . .

- We'll use **sample** *statistics* to [infer]{.hi-purple} something about population *parameters*
  - In practice, we'll only ever have a finite *sample distribution* of data
  - We *don't* know the *population distribution* of data
  - [Randomness problem]{.hi-purple}

# Data 101 {background-color="#314f4f" .centered}

## Data 101

::: columns
::: {.column width="50%"}
- [Data]{.hi} are information with context

- [Individuals]{.hi} are the entities described by a set of data 
    - e.g. persons, households, firms, countries 
:::

::: {.column width="50%"}
![](images/individual1.jpg)
:::
:::

## Data 101

::: columns
::: {.column width="50%"}
- [Variables]{.hi} are particular characteristics about an individual
    - e.g. age, income, profits, population, GDP, marital status, type of legal institutions

- [Observations]{.hi} or [cases]{.hi} are the separate individuals described by a collection of variables
    - e.g. for one individual, we have their age, sex, income, education, etc.  
- individuals and observations are *not necessarily* the same: 
    - e.g. we can have multiple observations on the same individual over time 
:::

::: {.column width="50%"}
![](images/individual1.jpg)
:::
:::

## Categorical Variables

::: columns
::: {.column width="50%"}
- [Categorical variables]{.hi} place an individual into one of several possible *categories*
    - e.g. sex, season, political party
    - may be responses to survey questions
    - can be quantitative (e.g. age, zip code)

- In `R`: `character` or `factor` type data
  - `factor` $\implies$ specific possible categories
:::

::: {.column width="50%"}
![](images/categoricaldata.png)
:::
:::

## Categorical Variables: Visualizing I

::: columns
::: {.column width="50%"}
```{r}
#| echo: true
#| eval: false
diamonds %>%
  count(cut) %>%
  mutate(frequency = n / sum(n),
         percent = round(frequency * 100, 2))
```

<br> 

```{r}
#| echo: false
diamonds %>%
  count(cut) %>%
  mutate(frequency = n / sum(n),
         percent = round(frequency * 100, 2)) %>%
knitr::kable(., format = "html", caption = "Summary of diamonds by cut")
```

:::

::: {.column width="50%"}
- Good way to represent categorical data is with a [frequency table]{.hi}

- [Count (n)]{.hi-purple}: total number of individuals in a category

- [Frequency]{.hi-purple}: **proportion** of a category's occurrence relative to all data
  - Multiply proportions by 100% to get **percentages**

:::
:::

## Categorical Variables: Visualizing II

- [Charts and graphs are *always* better ways to visualize data]{.hi-purple}

- A [bar graph]{.hi} represents categories as bars, with lengths proportional to the count or relative frequency of each category


::: columns
::: {.column width="50%"}
```{r}
#| echo: true
#| eval: false
ggplot(diamonds, aes(x=cut,
                     fill=cut))+
  geom_bar()+
  guides(fill=F)+
  theme_pander(base_family = "Fira Sans Condensed",
           base_size=20)
```

:::

::: {.column width="50%"}
```{r}
#| echo: false
ggplot(diamonds, aes(x=cut, fill=cut))+
  geom_bar()+
  guides(fill=F)+
  scale_y_continuous(limits = c(0,22000),
                     expand = c(0,0))+
  theme_pander(base_family = "Fira Sans Condensed",
           base_size=20)
```

:::
:::

## Categorical Data: Pie Charts

::: columns
::: {.column width="50%"}
- Avoid pie charts!

- People are *not* good at judging 2-d differences (angles, area)

- People *are* good at judging 1-d differences (length)

:::

::: {.column width="50%"}
![](images/badpiechart.png){width="750" fig-align="center"}
:::
:::



## Categorical Data: Alternatives to Pie Charts I

::: columns
::: {.column width="50%"}
- Try something else: a *stacked bar chart*

```{r, echo=T, eval=F}
diamonds %>%
  count(cut) %>%
ggplot(data = .)+
  aes(x = "",
      y = n)+
  geom_col(aes(fill = cut))+
  geom_label(aes(label = cut,
                 color = cut),
             position = position_stack(vjust = 0.5)
             )+
  guides(color = F,
         fill = F)+
  theme_void()
```
:::

::: {.column width="50%"}
```{r, fig.retina=3}
diamonds %>%
  count(cut) %>%
ggplot(data = .)+
  aes(x = "",
      y = n)+
  geom_col(aes(fill = cut))+
  geom_label(aes(label = cut,
                 color = cut),
             position = position_stack(vjust = 0.5)
             )+
  guides(color = F,
         fill = F)+
  theme_void()
```
:::
:::

## Categorical Data: Alternatives to Pie Charts II

::: columns
::: {.column width="50%"}
- Try something else: a *lollipop chart*

```{r, echo=T, eval=F}
diamonds %>%
  count(cut) %>%
  mutate(cut_name = as.factor(cut)) %>%
ggplot(., aes(x = cut_name, y = n, color = cut))+
 geom_point(stat="identity",
            fill="black",
            size=12)  +
  geom_segment(aes(x = cut_name, y = 0,
                   xend = cut_name,
                   yend = n), size = 2)+
  geom_text(aes(label = n),color="white", size=3) +
  coord_flip()+
  labs(x = "Cut")+
  theme_pander(base_family = "Fira Sans Condensed",
                base_size=20)+
  guides(color = F)
```
:::

::: {.column width="50%"}
```{r, fig.retina=3}
diamonds %>%
  count(cut) %>%
  mutate(cut_name = as.factor(cut)) %>%
ggplot(., aes(x = cut_name, y = n, color = cut))+
 geom_point(stat="identity",
            fill="black",
            size=12)  +
  geom_segment(aes(x = cut_name, y = 0,
                   xend = cut_name,
                   yend = n), size = 2)+
  geom_text(aes(label = n),color="white", size=3) +
  coord_flip()+
  labs(x = "Cut")+
  theme_pander(base_family = "Fira Sans Condensed",
                base_size=20)+
  guides(color = F)
```
:::
:::

## Categorical Data: Alternatives to Pie Charts III

::: columns
::: {.column width="50%"}
- Try something else: a *treemap*

```{r, echo=T, eval=F}
library(treemapify)
diamonds %>%
  count(cut) %>%
ggplot(., aes(area = n, fill = cut)) +
  geom_treemap() +
  guides(fill = FALSE) +
  geom_treemap_text(aes(label = cut),
                    colour = "white",
                    place = "topleft",
                    grow = TRUE)
```

:::

::: {.column width="50%"}
```{r, fig.retina=3}
library(treemapify)
diamonds %>%
  count(cut) %>%
ggplot(., aes(area = n, fill = cut)) +
  geom_treemap() +
  guides(fill = FALSE) +
  geom_treemap_text(aes(label = cut),
                    colour = "white",
                    place = "topleft",
                    grow = TRUE)
```
:::
:::

## Quantitative Data I

::: columns
::: {.column width="50%"}
- [Quantitative variables]{.hi} take on numerical values of equal units that describe an individual
    - Units: points, dollars, inches 
    - Context: GPA, prices, height

- We can mathematically manipulate *only* quantitative data
    - e.g. sum, average, standard deviation

- In `R`: `numeric` type data
  - `integer` if whole number
  - `double` if has decimals

:::

::: {.column width="50%"}
![](images/mathoperations.jpg)
:::
:::

## Discrete Data

::: columns
::: {.column width="50%"}
- [Discrete data]{.hi} are finite, with a countable number of alternatives 

- [Categorical]{.hi-purple}: place data into categories
  - e.g. letter grades: A, B, C, D, F
  - e.g. class level: freshman, sophomore, junior, senior

- [Quantitative]{.hi-purple}: integers
  - e.g. SAT Score, number of children, age (years)

:::

::: {.column width="50%"}
![](images/buildingblocks.jpeg)
:::
:::

## Continuous Data

::: columns
::: {.column width="50%"}
- [Continuous data]{.hi} are infinitely divisible, with an uncountable number of alternatives
    - e.g. weight, length, temperature, GPA

- Many discrete variables may be treated as if they are continuous
    - e.g. SAT scores (whole points), wages (dollars and cents)
    

:::

::: {.column width="50%"}
![](images/continuous.png){width="750" fig-align="center"}
:::
:::

## Spreadsheets

::: columns
::: {.column width="50%"}
```{r, example.spreadsheet.setup, echo=FALSE}
example <- tribble(
  ~id, ~name, ~age, ~sex, ~income,
  1, "John", 23, "Male", 41000,
  2, "Emile", 18, "Male", 52600,
  3, "Natalya", 28, "Female", 48000,
  4, "Lakisha", 31, "Female", 60200,
  5, "Cheng", 36, "Male", 81900
)
```

```{r, example.spreadsheet, results="asis", echo=FALSE}
example %>% 
  kableExtra::kbl() %>%
  kableExtra:: kable_styling(
    bootstrap_options = c("striped", "hover"), full_width = F)
```

:::

::: {.column width="50%"}
- The most common data structure we use is a [spreadsheet]{.hi}
    - In *R*: a `data.frame` or `tibble`
    
- A [row]{.hi-purple} contains data about all variables for a single [individual]{.hi-purple}

- A [column]{.hi-purple} contains data about a single [variable]{.hi-purple} across all individuals

:::
:::

## Spreadsheets: Indexing

::: columns
::: {.column width="50%"}

```{r, results="asis", echo=FALSE}
example %>% 
  kableExtra::kbl() %>%
  kableExtra:: kable_styling(
    bootstrap_options = c("striped", "hover"), full_width = F)
```

:::

::: {.column width="50%"}
- Each [cell]{.hi-purple} can be referenced by its row and column (in that order!), `df[row,column]`

<br>

```{r, echo=T}
example[3,2] # value in row 3, column 2
```

<br>

- Recall with `tidyverse` you can do this with `select()` and `filter()` or `slice()`
:::
:::

## Spreadsheets: Notation

- It is common to use some notation like the following:

- Let $\{x_1, x_2, \cdots, x_n\}$ be a simple data series on variable $X$
    - $n$ individual observations
    - $x_i$ is the value of the $i$<sup>th</sup> observation for $i=1,2,\cdots, n$

. . .

::: {.callout-tip}
## Quick Check

Let $x$ represent the score on a homework assignment:
$$75, 100, 92, 87, 79, 0, 95$$

1. What is $n$?
2. What is $x_1$?
3. What is $x_6$?
:::

## Datasets: Cross-Sectional


::: columns
::: {.column width="50%"}
```{r}
knitr::kable(example, format="html")
```

:::

::: {.column width="50%"}
- [Cross-sectional data]{.hi}: observations of individuals at a given point in time

- Each observation is a unique [individual]{.red}
$$x_{\color{#D7250E}{i}}$$

- Simplest and most common data 

- A ["snapshot"]{.hi-purple} to compare differences across individuals

:::
:::

## Datasets: Time-Series

::: columns
::: {.column width="50%"}
```{r}
Year<-c(1950,1960,1970,1980,1985)
GDP<-c(8.2,9.9,10.2,12.4,13.6)
Unemployment<-c(0.06,0.04,0.08,0.08,0.06)
CPI<-c(100,118,130,190,196)
example.timeseries<-data.frame(Year,GDP,Unemployment,CPI)
knitr::kable(example.timeseries, format="html")

```
:::

::: {.column width="50%"}
- [Time-series data]{.hi}: observations of the *same* individual(s) over time

- Each observation is a [time period]{.blue}
$$x_{\color{#0047AB}{t}}$$

- Often used for macroeconomics, finance, and forecasting

- Unique challenges for time series 

- A ["moving picture"]{.hi-purple} to see how individuals change over time 

:::
:::

## Datasets: Panel

::: columns
::: {.column width="50%"}
```{r}
City<-c("Philadelphia","Philadelphia","D.C.","D.C.", "New York")
Year<-c(1986, 1990, 1986, 1990, 1986)
Murders<-c(5, 8, 2, 10, 3)
Population<-c(3.7,4.2,0.250,0.275,6.4)
UR<-c(8.7,7.2,5.4,5.5,9.6)
example.panel<-data.frame(City,Year,Murders,Population,UR)
knitr::kable(example.panel, format="html")

```
:::
::: {.column width="50%"}
- [Panel]{.hi}, or [longitudinal]{.hi} dataset: a time-series for *each* cross-sectional entity
  - Must be *same* individuals over time

- Each obs. is an [individual]{.red} in a [time period]{.blue}
$$x_{\color{#D7250E}{i}\color{#0047AB}{t}}$$

- More common today for serious researchers; unique challenges and benefits

- A [combination]{.hi-purple} of “snapshot” comparisons over time

:::
:::

# Descriptive Statistics {background-color="#314f4f" .centered}

## Variables and Distributions

::: columns
::: {.column width="50%"}
- Variables take on different values, we can describe a variable's [distribution]{.hi} (of these values)

- We want to *visualize* and *analyze* distributions to search for meaningful patterns using **statistics** 

:::
::: {.column width="50%"}
![](images/statsgraphs.jpg)
:::
:::


## Two Branches of Statistics

::: columns
::: {.column width="50%"}
- Two main branches of statistics:

1. [Descriptive Statistics:]{.hi} describes or summarizes the properties of a sample

2. [Inferential Statistics:]{.hi} infers properties about a larger population from the properties of a sample
  - We'll encounter inferential statistics mainly in the context of regression later.

:::
::: {.column width="50%"}
![](images/statsgraphs.jpg)
:::
:::

## Histogram

::: columns
::: {.column width="50%"}
- A common way to present a *quantitative* variable's distribution is a [histogram]{.hi}
    - The quantitative analog to the bar graph for a categorical variable

- Divide up values into **bins** of a certain size, and count the number of values falling within each bin, representing them visually as bars 

:::
::: {.column width="50%"}
```{r}
#| out-width: "100%"
#| fig-align: "center"
#| fig-width: 6
set.seed(20)

df<-tibble(x=rnorm(500,0,1))

ggplot(df, aes(x = x))+
  geom_histogram(color="white",
                 fill = "#e64173",
                 binwidth = 0.2)+
  scale_y_continuous(limits=c(0,50),
                     expand=c(0,0))+
  theme_bw(base_family = "Fira Sans Condensed", base_size=20)+
  labs(caption = "Bin width = 0.20")
```
:::
:::

## Histogram: Bin Size

::: columns
::: {.column width="50%"}
- A common way to present a *quantitative* variable's distribution is a [histogram]{.hi}
    - The quantitative analog to the bar graph for a categorical variable

- Divide up values into **bins** of a certain size, and count the number of values falling within each bin, representing them visually as bars
  - Changing the **bin-width** will affect the bars

:::
::: {.column width="50%"}
```{r}
#| out-width: "100%"
#| fig-align: "center"
#| fig-width: 6
set.seed(20)

df<-tibble(x=rnorm(500,0,1))

ggplot(df, aes(x = x))+
  geom_histogram(color="white",
                 fill = "#e64173",
                 binwidth = 0.5)+
  scale_y_continuous(limits=c(0,100),
                     expand=c(0,0))+
  theme_bw(base_family = "Fira Sans Condensed", base_size=20)+
  labs(caption = "Bin width = 0.50")
```
:::
:::


## Histogram: Example

::: columns
::: {.column width="50%"}

::: {.callout-tip}
## Example
A class of 13 students takes a quiz (out of 100 points) with the following results:
$$\{ 0, 62, 66, 71, 71, 74, 76, 79, 83, 86, 88, 93, 95 \}$$
:::

:::
::: {.column width="50%"}
```{r}
quizzes <- tibble(scores = c(0,62,66,71,71,74,76,79,83,86,88,93,95))

```
:::
:::

## Histogram: Example

::: columns
::: {.column width="50%"}

::: {.callout-tip}
## Example
A class of 13 students takes a quiz (out of 100 points) with the following results:
$$\{ 0, 62, 66, 71, 71, 74, 76, 79, 83, 86, 88, 93, 95 \}$$
:::

```{r}
#| echo: true
#| eval: false
ggplot(quizzes,aes(x=scores))+
  geom_histogram(breaks = seq(0,100,10),
                 color = "white",
                 fill = "#e64173")+
  scale_x_continuous(breaks = seq(0,100,10))+
  scale_y_continuous(limits = c(0,6), expand = c(0,0))+
  labs(x = "Scores",
       y = "Number of Students")+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=20)
```

:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig-width: 6
#| fig-align: center

ggplot(quizzes,aes(x=scores))+
  geom_histogram(breaks = seq(0,100,10),
                 color = "white",
                 fill = "#e64173")+
  scale_x_continuous(breaks = seq(0,100,10))+
  scale_y_continuous(limits = c(0,6), expand = c(0,0))+
  labs(x = "Scores",
       y = "Number of Students")+
  ggthemes::theme_pander(base_family = "Fira Sans Condensed",
           base_size=20)
```
:::
:::

## Descriptive Statistics

::: columns
::: {.column width="50%"}
- We are often interested in the *shape* or *pattern* of a distribution, particularly: 
    - Measures of **center**
    - Measures of **dispersion**
    - **Shape** of distribution 

:::
::: {.column width="50%"}
![](images/statsgraphs.jpg)
:::
:::

# Measures of Center {background-color="#314f4f" .centered}

## Mode

- The [mode]{.hi} of a variable is simply its most frequent value

- A variable can have multiple modes

. . .

::: {.callout-tip}
## Example
A class of 13 students takes a quiz (out of 100 points) with the following results:
$$\{ 0, 62, 66, \mathbf{71}, \mathbf{71}, 74, 76, 79, 83, 86, 88, 93, 95 \}$$

:::

## Mode

- There is no dedicated `mode()` function in `R`, surprisingly

- A workaround in `dplyr`: 

::: columns
::: {.column width="50%"}
```{r}
#| echo: true
#| eval: false
quizzes %>%
  count(scores) %>%
  arrange(desc(n))
```

:::
::: {.column width="50%"}
```{r}
#| echo: false
#| eval: true
quizzes %>%
  count(scores) %>%
  arrange(desc(n)) %>%
  rmarkdown::paged_table(., options = list(rows.print = 5))
```

:::
:::

## Multi-Modal Distributions

::: columns
::: {.column width="50%"}
- Looking at a histogram, the modes are the "peaks" of the distribution
    - Note: depends on how wide you make the bins!

- May be unimodal, bimodal, trimodal, etc

:::
::: {.column width="50%"}
```{r, fig.retina=3}
#| fig-width: 6
#| fig-align: center

tibble(scores=c(0,33,33,33,33,35,62,66,71,71,74,76,79,83,86,88,93,95)) %>%
  ggplot(data = .,
         aes(x=scores))+
  geom_histogram(breaks = seq(0,100,10),
                 color = "white",
                 fill = "#e64173")+
  scale_x_continuous(breaks = seq(0,100,10))+
  scale_y_continuous(limits = c(0,6.5),
                     expand = c(0,0))+
  labs(x = "Scores",
       y = "Number of Students")+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=20)
```

:::
:::

## Symmetry and Skew I

::: columns
::: {.column width="50%"}
- A distribution is [symmetric]{.hi-purple} if it looks roughly the same on either side of the "center"

- The thinner ends (far left and far right) are called the **tails** of a distribution

:::
::: {.column width="50%"}
```{r}
#| fig-width: 6
#| fig-align: center

symmetric<-data.frame(x=rnorm(500,25,10))

ggplot(symmetric,(aes(x)))+
    geom_histogram(stat="bin",bins=10,color="white",fill="#e64173")+
  scale_y_continuous(limits = c(0,140),
                     expand = c(0,0))+
    theme_bw(base_family = "Fira Sans Condensed",
           base_size=20)

```
:::
:::

## Symmetry and Skew I

::: columns
::: {.column width="50%"}
- If one tail stretches farther than the other, distribution is [skewed]{.hi-purple} in the direction of the longer tail
  - In this example, skewed to the **left**

:::
::: {.column width="50%"}
```{r}
#| fig-width: 6
#| fig-align: center

skew.left<-data.frame(x=rbeta(500,5,1))

ggplot(skew.left,(aes(x)))+
    geom_histogram(stat="bin",bins=10,color="white",fill="#e64173")+
  scale_y_continuous(limits = c(0,175),
                     expand = c(0,0))+
    theme_bw(base_family = "Fira Sans Condensed",
           base_size=20)

```
:::
:::

## Outliers

::: columns
::: {.column width="50%"}
- [Outlier]{.hi}: “extreme” value that does not appear part of the general pattern of a distribution

- Can strongly affect descriptive statistics

- Might be the most informative part of the data

- Could be the result of errors

- Should always be explored and discussed!
:::
::: {.column width="50%"}
```{r}
#| fig-width: 6
#| fig-align: center

ggplot(quizzes,aes(x=scores))+
  geom_histogram(breaks = seq(0,100,10),
                 color = "white",
                 fill = "#e64173")+
  scale_x_continuous(breaks = seq(0,100,10))+
  scale_y_continuous(limits = c(0,6), expand = c(0,0))+
  labs(x = "Scores",
       y = "Number of Students")+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=20)
```
:::
:::

## Arithmetic Mean (Population)


- The natural measure of the center of a *population*'s distribution is its ["average"]{.hi} or [arithmetic mean $\mu$]{.hi}

$$\mu=\frac{x_1+x_2+...+x_N}{N} = \frac{1}{N} \sum^N_{i=1} x_i$$

- For $N$ values of variable $x$, "mu" is the sum of all individual $x$ values $(x_i)$ from 1 to $N$, divided by the $N$ number of values^[Note the mean need not be an actual value of the data!]


## Arithmetic Mean (Sample)

- When we have a *sample*, we compute the [sample mean $\bar{x}$]{.hi}

$$\bar{x}=\frac{x_1+x_2+...+x_n}{n} = \frac{1}{n} \sum^n_{i=1} x_i$$

- For $n$ values of variable $x$, "x-bar" is the sum of all individual $x$ values $(x_i)$ divided by the $n$ number of values

## Arithmetic Mean (Sample)

::: {.callout-tip}
## Example

$$\{0, 62, 66, 71, 71, 74, 76, 79, 83, 86, 88, 93, 95\}$$
:::

. . .

\begin{align*}
\bar{x}&=\frac{1}{13}(0+62+66+71+71+74+76+79+83+86+88+93+95)\\
\bar{x}&=\frac{944}{13}\\
\bar{x}&=72.62\\
\end{align*}

. . .

```{r}
#| echo: true
quizzes %>%
  summarize(mean = mean(scores))
```

## Arithmetic Mean: Affected by Outliers

::: {.callout-tip}
## Example: If we drop the outlier (0)

$$\{62, 66, 71, 71, 74, 76, 79, 83, 86, 88, 93, 95\}$$
:::

. . .

\begin{align*}
\bar{x}&=\frac{1}{12}(62+66+71+71+74+76+79+83+86+88+93+95)\\
&=\frac{944}{12}\\
&=78.67\\
\end{align*}

. . .

```{r}
#| echo: true
quizzes %>%
  filter(scores > 0) %>%
  summarize(mean = mean(scores))
```

## Median

$$\{0, 62, 66, 71, 71, 74, \mathbf{76}, 79, 83, 86, 88, 93, 95\}$$

- The [median]{.hi} is the midpoint of the distribution
    - 50% to the left of the median, 50% to the right of the median

- Arrange values in numerical order
    - For odd $n$: median is middle observation
    - For even $n$: median is average of two middle observations

## Mean, Median, and Outliers

![](images/meanoutliers.jpg){fig-align="center"}

## Mean, Median, Symmetry, & Skew I

::: columns
::: {.column width="50%"}
- Symmetric distribution: mean $\approx$ median

```{r}
#| echo: false
symmetric <- tibble(x=c(1,2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 6, 6, 7))
```

```{r}
#| echo: true
symmetric %>%
  summarize(mean = mean(x),
            median = median(x))
```

:::
::: {.column width="50%"}
```{r}
#| fig-width: 8
#| fig-align: center
ggplot(symmetric,aes(x=x))+
  geom_histogram(breaks=seq(0,7,1),color="white",fill="#e64173")+
  geom_vline(aes(xintercept=mean(x)), color="red", linetype="dashed", size=1)+
  geom_vline(aes(xintercept=median(x)), color="green", linetype="dotted", size=2)+
  geom_label(aes(x=mean(x),y=4), color = "red", label = "mean")+
  geom_label(aes(x=median(x),y=4.5), color = "green", label = "median")+
  scale_x_continuous(breaks=seq(0,7,1))+
  scale_y_continuous(limits = c(0,5.5),
                     expand = c(0,0))+
      theme_bw(base_family = "Fira Sans Condensed",
           base_size=20)

```
:::
:::

## Mean, Median, Symmetry, & Skew II

::: columns
::: {.column width="50%"}
- Left-skewed: mean $<$ median

```{r}
#| echo: false
leftskew <- tibble(x=c(1,2,3,4,4,4,5,5,6,6,6,7,7))
```

```{r}
#| echo: true
leftskew %>%
  summarize(mean = mean(x),
            median = median(x))
```

:::
::: {.column width="50%"}
```{r}
#| fig-width: 8
#| fig-align: center

ggplot(leftskew,aes(x=x))+
  geom_histogram(breaks=seq(0,7,1),color="white",fill="#e64173")+
  geom_vline(aes(xintercept=mean(x)), color="red", linetype="dashed", size=1)+
  geom_vline(aes(xintercept=median(x)), color="green", linetype="dotted", size=2)+
  geom_label(aes(x=mean(x),y=4), color = "red", label = "mean")+
  geom_label(aes(x=median(x),y=4.5), color = "green", label = "median")+
  scale_x_continuous(breaks=seq(0,7,1))+
  scale_y_continuous(limits = c(0,5.5),
                     expand = c(0,0))+
      theme_bw(base_family = "Fira Sans Condensed",
           base_size=20)

```
:::
:::

## Mean, Median, Symmetry, & Skew III

::: columns
::: {.column width="50%"}
- Right-skewed: mean $>$ median

```{r}
#| echo: false
rightskew <- tibble(x=c(1,1,2,2,2,3,3,4,4,4,5,6,7))
```

```{r}
#| echo: true
rightskew %>%
  summarize(mean = mean(x),
            median = median(x))
```

:::
::: {.column width="50%"}
```{r}
#| fig-width: 8
#| fig-align: center

ggplot(rightskew,aes(x=x))+
  geom_histogram(breaks=seq(0,7,1),color="white",fill="#e64173")+
  geom_vline(aes(xintercept=mean(x)), color="red", linetype="dashed", size=1)+
  geom_vline(aes(xintercept=median(x)), color="green", linetype="dotted", size=2)+
  geom_label(aes(x=mean(x),y=4), color = "red", label = "mean")+
  geom_label(aes(x=median(x),y=4.5), color = "green", label = "median")+
  scale_x_continuous(breaks=seq(0,7,1))+
  scale_y_continuous(limits = c(0,5.5),
                     expand = c(0,0))+
      theme_bw(base_family = "Fira Sans Condensed",
           base_size=20)

```
:::
:::

# Measures of Dispersion {background-color="#314f4f" .centered}

## Range

- The more *variation* in the data, the less helpful a measure of central tendency will tell us

- Beyond just the center, we also want to measure the spread

- Simplest metric is [range]{.hi} $=max-min$

## Five Number Summary I

- Common set of summary statistics of a distribution: ["five number summary"]{.hi}:

::: columns
::: {.column width="55%"}
1. Minimum value
2. 25<sup>th</sup> percentile $(Q_1$, median of first 50% of data)
3. 50<sup>th</sup> percentile (median, $Q_2)$
4. 25<sup>th</sup> percentile $(Q_3$, median of last 50% of data)
5. Maximum value

:::
::: {.column width="45%"}

```{r}
#| echo: true
# Base R summary command
summary(quizzes$scores)
```

<br>

```{r}
#| echo: true
quizzes %>% # dplyr
  summarize(Min = min(scores),
            Q1 = quantile(scores, 0.25),
            Median = median(scores),
            Q3 = quantile(scores, 0.75),
            Max = max(scores))
```
:::
:::

## Five Number Summary II

- The $n$<sup>th</sup> [percentile]{.hi-purple} of a distribution is the value that places $n$ percent of values beneath it

```{r}
#| echo: true
quizzes %>%
  summarize("37th percentile" = quantile(scores,0.37))
```

## Boxplot I

::: columns
::: {.column width="50%"}
- [Boxplots]{.hi} are a great way to visualize the 5 number summary

- **Height of box**: $Q_1$ to $Q_3$ (known as [interquartile range (IQR)]{.hi-purple}, middle 50% of data)

- **Line inside box**: median (50<sup>th</sup> percentile)

- **"Whiskers"** identify data within $1.5 \times IQR$

- Points *beyond* whiskers are [outliers]{.hi-purple}
    - common definition: Outlier $>1.5 \times IQR$

:::
::: {.column width="50%"}
```{r}
quizzes %>%
  ggplot(data = .)+
  aes(x = "",
      y = scores)+
  geom_boxplot()+
  labs(x = "Quiz")+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=20)

```
:::
:::

## Boxplot Comparisons I

- Boxplots (and five number summaries) are great for comparing two distributions

::: {.callout-tip}
## Example

\begin{align*} \text{Quiz 1}&: \{0, 62, 66, 71, 71, 74, 76, 79, 83, 86, 88, 93, 95\}	\\
			\text{Quiz 2}&: \{50, 62, 72, 73, 79, 81, 82, 82, 86, 90, 94, 98, 99\} \\ \end{align*}

:::

```{r}
#| echo: false
quizzes_new <- quizzes %>%
  rename(quiz_1 = scores) %>% # rename to Quiz 1
  mutate(student = 1:13) %>% # add students to track over 2 quizzes
  select(student, everything()) %>% # move students to front
  bind_cols(quiz_2 = c(50, 62, 72, 73, 79, 81, 82, 82, 86, 90, 94, 98, 99))
```

## Boxplot Comparisons II

::: columns
::: {.column width="50%"}
```{r}
#| echo: true
quizzes_new %>% summary()
```
:::
::: {.column width="50%"}
```{r}
#| echo: false
#| fig-width: 8
#| fig-align: center

quizzes_long<-gather(quizzes_new, key="student", value="score")

ggplot(data = quizzes_long)+
  aes(x = student,
      y = score,
      fill = student)+
  geom_boxplot()+
    labs(x = "Quiz")+
  scale_x_discrete(labels=c("Quiz 1", "Quiz 2"))+
  scale_fill_viridis_d()+
  guides(fill=F)+
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=20)
```

:::
:::


## Measures of Dispersion: Deviations

- Every observation $i$ [deviates]{.hi-purple} from the mean of the data: 
$$deviation_i = x_i-\mu	$$

- There are as many deviations as there are data points $(n)$

- We can measure the *average* or [standard deviation]{.hi} of a variable from its mean

- Before we get there...

## Variance (Population)

- The [population variance $\sigma^2$]{.hi} of a *population* distribution measures the average of the *squared* deviations from the *population* mean $(\mu)$

$$\sigma^2 = \frac{1}{N}\displaystyle\sum^N_{i=1} (x_i-\mu)^2$$

. . .

- Why do we square deviations?

. . .

- What are these units? 

## Standard Deviation (Population)

- Square root the variance to get the [population standard deviation $\sigma$]{.hi}, the average deviation from the population mean (in same units as $x$)

$$\sigma=\sqrt{\sigma^2}=\sqrt{\frac{1}{N}\displaystyle\sum^N_{i=1} (x_i-\mu)^2	}$$

## Variance (Sample)

- The [sample variance $s^2$]{.hi} of a *sample* distribution measures the average of the *squared* deviations from the *sample* mean $(\bar{x})$

$$\sigma^2 = \frac{1}{n-1}\displaystyle\sum^n_{i=1} (x_i-\bar{x})^2$$

. . .

- Why do we divide by $n-1$?

## Standard Deviation (Sample)

- Square root the sample variance to get the [sample standard deviation $s$]{.hi}, the average deviation from the *sample* mean (in same units as $x$)

$$s=\sqrt{s^2}=\sqrt{\frac{1}{n-1}\displaystyle\sum^n_{i=1} (x_i-\bar{x})^2	}$$

::: {.callout-tip}
## Example

Calculate the sample standard deviation for the following series: 

$$\{2, 4, 6, 8, 10 \}$$
:::

. . .

```{r}
#| echo: true
sd(c(2,4,6,8,10))

```

## The Steps to Calculate `sd()`, Coded I

```{r}
#| echo: true
#  first let's save our data in a tibble
sd_example <- tibble(x = c(2,4,6,8,10))
```

<br>

```{r}
#| echo: true
# first find the mean (just so we know)

sd_example %>%
  summarize(mean(x))
```

<br>

```{r}
#| echo: true
# now let's make some more columns:
sd_example <- sd_example %>%
  mutate(deviations = x - mean(x), # take deviations from mean
         deviations_sq = deviations^2) # square them
```

## The Steps to Calculate `sd()`, Coded II

```{r}
#| echo: true
sd_example # see what we made
```

## The Steps to Calculate `sd()`, Coded III

```{r}
#| echo: true
sd_example %>%
  # sum the squared deviations
  summarize(sum_sq_devs = sum(deviations_sq), 
            # divide by n-1 to get variance
            variance = sum_sq_devs/(n()-1), 
            # square root to get sd
            std_dev = sqrt(variance)) 

```

## Sample Standard Deviation: You Try

::: {.callout-tip}
## Example

Calculate the sample standard deviation for the following series: 

$$\{1, 3, 5, 7 \}$$
:::

. . .

```{r}
#| echo: true
sd(c(1,3,5,7))
```

## Descriptive Statistics: Populations vs. Samples

::: columns
::: {.column width="50%"}
#### Population parameters

- **Population size**: $N$

- **Mean**: $\mu$

- **Variance**: $\sigma^2=\frac{1}{N} \displaystyle\sum^N_{i=1} (x_i-\mu)^2$

- **Standard deviation**: $\sigma = \sqrt{\sigma^2}$

:::
::: {.column width="50%"}
#### Sample statistics

- **Population size**: $n$

- **Mean**: $\bar{x}$

- **Variance**: $s^2=\frac{1}{n-1} \displaystyle\sum^n_{i=1} (x_i-\bar{x})^2$

- **Standard deviation**: $s = \sqrt{s^2}$

:::
:::
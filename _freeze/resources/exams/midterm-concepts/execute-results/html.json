{
  "hash": "719ec776377a31afbaeedf549fd95100",
  "result": {
    "markdown": "---\ntitle: \"Midterm Concepts\"\neditor: visual\nexecute:\n  freeze: auto\n---\n\n\n\n\n# OLS Regression\n\nBivariate data and associations between variables (e.g. $X$ and $Y$)\n\n-   Apparent relationships are best viewed by looking at a scatterplot\n\n-   Check for associations to be positive/negative, weak/strong, linear/nonlinear, etc\n\n    -   $Y$: dependent variable\n\n    -   $X$: independent variable\n\n-   Correlation coefficient ($r$) can quantify the strength of an association\n\n    $$\n    r_{X,Y}=\\frac{1}{n-1} \\sum^n \\bigg(\\frac{X_i-\\bar{X}}{s_X}\\bigg) \\bigg(\\frac{Y_i-\\bar{Y}}{s_Y}\\bigg) = \\frac{\\displaystyle \\sum^n Z_X Z_Y}{n-1}  \n    $$\n\n    -   $-1 \\leq r \\leq 1$ and $r$ only measures *linear* associations\n\n    -   $|r|$ closer to 1 imply stronger correlation (near a perfect straight line)\n\n    -   Correlation does not imply causation! Might be confounding or lurking variables (e.g.\\$Z\\$) affecting $X$ and/or $Y$\n\nPopulation regression model\n\n\n$$\nY_i=\\beta_0+\\beta_1X_i+u_i\n$$\n\n\n-   $\\beta_1$: $\\frac{\\Delta Y}{\\Delta X}$: the slope between \\$X\\$ and \\$Y\\$, number of units of $Y$ from a 1 unit change in $X$\n\n-   $\\beta_0$ is the $Y$-intercept: literally, value of $Y$ when $X=0$\n\n-   $u_i$ is the error, difference between actual value of $Y|X$ vs. predicted value of $\\hat{Y}$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](midterm-concepts_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nOrdinary Least Squares (OLS) regression model\n\n\n$$\nY_i = \\hat{\\beta}_0+\\hat{\\beta}_1 X_i + u_i \n$$\n\n$$\n\\hat{Y_i}=\\hat{\\beta_0}+\\hat{\\beta_1}X_i\n$$\n\n$$\n\\hat{u}_i = Y_i-\\hat{Y}_i\n$$\n\n\n-   OLS estimators $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ estimate population regression line from sample data\n\n-   Minimize sum of squared errors (SSR) $min\\displaystyle \\sum^n \\hat{u}_i^2$\n\n-   OLS regression line\n\n\n$$\n\\hat{\\beta_1} = \\frac{cov(X,Y)}{var(X)}=\\frac{\\sum (X_i-\\bar{X})(Y_i-\\bar{Y})}{\\sum (X_i-\\bar{X})^2}=r_{X,Y}\\frac{s_Y}{s_X}\n$$\n\n$$\n\\hat{\\beta_0} = \\bar{Y}-\\hat{\\beta_1}\\bar{X}        \n$$\n\n\n# Measures of Fit\n\n-   $R^2$: fraction of total variation on $Y$ explained by variation in $X$ according to model\n\n\n$$\n\\begin{align*}\nR^2 & = \\frac{SSM}{SST} \\\\\nR^2 & = 1 - \\frac{SSR}{SST} \\\\\nR^2 & = r_{X,Y}^2 \\\\\n\\end{align*}\n$$\n\n\n-   Where\n\n    -   $SSM = \\sum (\\hat{Y}_i - \\bar{Y}_i)^2$\n\n    -   $SST = \\sum(Y_i - \\bar{Y}_i)^2$\n\n    -   $SSR = \\sum u_i^2$\n\n<!-- -->\n\n-   Standard error of the regression (or residuals), SER: average size of $\\hat{u}_i$, i.e. average distance between points and the regression line\n\n    $$\n    SER \\, (\\sigma_{\\hat{u}_i})= \\frac{SSR}{n-2} = \\frac{\\sum \\hat{u_i}^2}{n-2} \n    $$\n\n# Sampling Distribution of $\\hat{\\beta}_1$\n\n![](/slides/2.5-slides_files/figure-revealjs/unnamed-chunk-6-1.png)\n\n$\\hat{\\beta_1}$ is a random variable, so it has its own sampling distribution with mean $\\mathbb{E}[\\hat{\\beta_1}]$ and standard error $se[\\hat{\\beta_1}]$\n\n-   Mean of OLS estimator $\\hat{\\beta_1}$ & Bias: Endogeneity & Exogeneity\n\n    -   $X$ is **exogenous** if it is not correlated with the error term\n\n        $$\n        \\begin{align*} cor(X,u) &=0 \\\\\n        \\mathbb{E}[u|X] &=0 \\\\\n        \\end{align*}\n        $$\n\n        -   equivalently, knowing $X$ should tell us nothing about $u$ (*zero conditional mean* assumption)\n\n        -   if $X$ is exogenous, OLS estimate of $\\beta_1$ is *unbiased*\n\n            $$\n            E[\\hat{\\beta}_1]=\\beta_1\n            $$\n\n    -   $X$ is **endogenous** if it is correlated with the error term\n\n        $$\n        cor(X,u) \\neq 0\n        $$\n\n        -   If $X$ is endogenous, OLS estimate of $\\beta_1$ is *biased*:\n\n            $$\n            \\mathbb{E}[\\hat{\\beta}_1] = \\beta_1 + \\underbrace{cor(X,u)\\frac{\\sigma_u}{\\sigma_X}}_{bias}\n            $$\n\n            -   Can measure strength and direction (+ or -) of bias\n\n            -   Note if unbiased, $cor(X,u)=0$, so $E[\\hat{\\beta_1}]=\\beta_1$\n\n    -   Assumptions about u\n\n        1.  The mean of the errors is 0\n\n            $$\n            \\mathbb{E}[u_i] = 0\n            $$\n\n        2.  The variance of the errors is constant over all values of $X$ (homoskedasticity)\n\n            $$\n            var[u_i|X_i]=\\sigma_u^2\n            $$\n\n        3.  Errors are not correlated across observations $i$ and $j$ (no autocorrelation)\n\n            $$\n            cor(u_i,u_j) = 0\n            $$\n\n        4.  There is no correlation between $X$ and $u$, i.e. the model is exogenous\n\n            $$\n            \\begin{align*} cor(X,u) &=0 \\\\\n            \\mathbb{E}[u|X] &=0 \\\\\n            \\end{align*}\n            $$\n\n-   Precision of OLS estimator $\\hat{\\beta}_1$ measures uncertainty/variability of estimate\n\n    $$\n    \\begin{align*}\n    var[\\hat{\\beta}_1]&=\\frac{SER^2}{n\\times var(X)}\\\\\n    se[\\hat{\\beta}_1]&=\\sqrt{var[\\hat{\\beta}_1]} \\\\\n    \\end{align*}\n    $$\n\n    -   Affected by three factors:\n\n        -   Model fit, (SER)\n\n        -   Sample size, $n$\n\n        -   Variation in $X$\n\n    -   Heteroskedasticity & Homoskedasticity\n\n        -   Homoskedastic errors ($\\hat{u}_i$) have the same variance over all values of $X$\n\n        -   Heteroskedastic errors ($\\hat{u}_i$) have different variance over values of $X$\n\n            -   Heteroskedasticity does *not* bias our estimates, but incorrectly lowers variance & standard errors (inflating \\$t\\$-statistics and significance!)\n\n            -   Can correct for heteroskedasticity by using robust standard errors\n\n# Hypothesis Testing of $\\beta_1$\n\n-   $H_0: \\beta_1=\\beta_{1,0}$, often $H_0: \\beta_1=0$\n\n-   Two sided alternative $H_1: \\beta_1 \\neq 0$\n\n-   One sided alternatives $H_1: \\beta_1 > 0$ or $H_2: \\beta_1 < 0$\n\n-   $t$-statistic\n\n\n$$\nt=\\frac{\\hat{\\beta_1}-\\beta_{1,0}}{se(\\hat{\\beta_1})}\n$$\n\n\n-   Compare $t$ against critical value $t$\\*, or compute $p$-value as usual\n\n-   Confidence intervals (95%): $\\hat{\\beta_1} \\pm 1.96 \\left(se(\\hat{\\beta_1})\\right)$\n",
    "supporting": [
      "midterm-concepts_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
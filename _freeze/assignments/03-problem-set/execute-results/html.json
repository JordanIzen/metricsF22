{
  "hash": "5fa8605b5f1166e0e980c4dc96006379",
  "result": {
    "markdown": "---\ntitle: \"Problem Set 3\"\nexecute:\n  freeze: auto\n---\n\n\n::: callout-warning\nThis assignment is due by Friday October 14 by email.\n:::\n\nPlease read the [instructions](/assignments/problem-sets.html) for completing and submitting homeworks. \n\n<p style=\"text-align:center\">\n\n<p style=\"text-align:center\"><a target=\"_blank\" href=\"/files/assignment/03-problem-set-pdf.pdf\"><span class=\"btn btn-primary btn-lg\"><i class=\"fas fa-file-pdf\"></i> PDF</a></span> <a target=\"_blank\" href=\"/files/assignment/03-problem-set.zip\"><span class=\"btn btn-primary btn-lg\"><i class=\"fas fa-file-archive\"></i> R Project</a></span> <a target=\"_blank\" href=\"https://rstudio.cloud/spaces/270168/content/4691729\"><span class=\"btn btn-primary btn-lg\"><i class=\"fas fa-cloud\"></i> R Studio Cloud</a></span></p>\n\n</p>\n\nThe <i class=\"fas fa-file-pdf\"></i> PDF is useful if you want to print out the problem set and write on it. The <i class=\"fas fa-file-archive\"></i> R Project is a zipped `.zip` file which contains a <i class=\"fab fa-markdown\"></i> `.qmd` file to write answers in, and the data, all in a logical working directory. ([See this resource](/resources/zipping.qmd) for help unzipping files). You can also just write an `.R` file in the project if you don't want to use markdown. If you use the <i class=\"fas fa-cloud\"></i> cloud project, I have already installed `tidyverse` and `tinytex` (to produce pdfs).\n\n# Theory and Concepts\n\n## Question 1\n\nIn your own words, describe what exogeneity and endogeneity mean, and how they are related to bias in our regression. What things can we learn about the bias if we know $X$ is endogenous?\n\n## Question 2\n\nIn your own words, describe what $R^2$ means. How do we calculate it, what does it tell us, and how do we interpret it?\n\n## Question 3\n\nIn your own words, describe what the standard error of the regression ($SER$) means. How do we calculate it, what does it tell us, and how do we interpret it?\n\n## Question 4\n\nIn your own words, describe what homoskedasticity and heteroskedasticity mean: both in ordinary English, and in terms of the graph of the OLS regression line.\n\n## Question 5\n\nIn your own words, describe what the variation in $\\hat{\\beta_1}$ (either variance or standard error) means, or is measuring. What three things determine the variation, and in what way?\n\n## Question 6\n\nIn your own words, describe what a p-value means, and how it is used to establish statistical significance.\n\n## Question 7\n\nA researcher is interested in examining the impact of illegal music downloads on commercial music sales. The author collects data on commercial sales of the top 500 singles from 2017 (Y) and the number of downloads from a web site that allows 'file sharing' (X). The author estimates the following model:\n\n\n$$\n\\text{music sales}_i = \\beta_0+\\beta_1 \\text{illegal downloads}_i + u_i\n$$\n\n\nThe author finds a large, positive, and statistically significant estimate of $\\hat{\\beta_1}$. The author concludes these results demonstrate that illegal downloads actually boost music sales. Is this an unbiased estimate of the impact of illegal music on sales? Why or why not? Do you expect the estimate to overstate or understate the true relationship between illegal downloads and sales?\n\n# Theory Problems\n\nFor the following questions, please show all work and explain answers as necessary. You may lose points if you only write the correct answer. You may use R to verify your answers, but you are expected to reach the answers in this section \"manually.\"\n\n## Question 8\n\nA researcher wants to estimate the relationship between average weekly earnings ($AWE$, measured in dollars) and $Age$ (measured in years) using a simple OLS model. Using a random sample of college-educated full-time workers aged 25-65 yields the following:\n\n\n$$\n\\widehat{AWE} = 696.70+9.60 \\, Age\n$$\n\n\n### Part A\n\nInterpret what $\\hat{\\beta_0}$ means in this context.\n\n### Part B\n\nInterpret what $\\hat{\\beta_1}$ means in this context.\n\n### Part C\n\nThe $R^2=0.023$ for this regression. What are the units of the $R^2$, and what does this mean?\n\n### Part D\n\nThe $SER, \\, \\hat{\\sigma_u}=624.1$ for this regression. What are the units of the SER in this context, and what does it mean? Is the SER large in the context of this regression?\n\n### Part E\n\nSuppose Maria is 20 years old. What is her predicted $\\widehat{AWE}$?\n\n### Part F\n\nSuppose the data shows her *actual* $AWE$ is $430. What is her residual? Is this a relatively good or a bad prediction? Hint: compare your answer here to your answer in Part D.\n\n### Part G\n\nWhat does the error term, $u_i$ represent in this case? What might individuals have different values of $\\hat{u}_i$?\n\n### Part H\n\nDo you think that $Age$ is exogenous? Why or why not? Would we expect $\\hat{\\beta_1}$ to be too large or too small?\n\n## Question 9\n\nSuppose a researcher is interested in estimating a simple linear regression model:\n\n\n$$\nY_i=\\beta_0+\\beta_1X_i+u_i\n$$\n\n\nIn a sample of 48 observations, she generates the following descriptive statistics:\n\n- $\\bar{X}=30$\n- $\\bar{Y}=63$\n- $\\displaystyle\\sum^n_{i=1}(X_i-\\bar{X})^2= 6900$\n- $\\displaystyle\\sum^n_{i=1}(Y_i-\\bar{Y})^2= 29000$\n- $\\displaystyle\\sum^n_{i=1}(X_i-\\bar{X})(Y_i-\\bar{Y})=13800$\n- $\\displaystyle\\sum^n_{i=1}\\hat{u}^2=1656$\n\n### Part A\n\nWhat is the OLS estimate of $\\hat{\\beta_1}$?\n\n### Part B\n\nWhat is the OLS estimate of $\\hat{\\beta_0}$?\n\n### Part C\n\nSuppose the OLS estimate of $\\hat{\\beta_1}$ has a standard error of $0.072$. Could we probably reject a null hypothesis of $H_0: \\beta_1=0$ at the 5% level?\n\n### Part D\n\nCalculate the $R^2$ for this model. How much variation in $Y$ is explained by our model?\n\n# R Questions\n\nAnswer the following questions using R. When necessary, please write answers in the same document (rendered to html or pdf, typed .doc(x), or handwritten) as your answers to the above questions. Be sure to include (email or print an .R file, or show in your rendered quarto document) your code and the outputs of your code with the rest of your answers.\n\n### Question 10\n\n- [<i class=\"fas fa-table\"></i> `MLBattend.csv`](http://metricsf22.classes.ryansafner.com/files/data/MLBattend.csv)\n\nDownload the MLBattend dataset. This data contains data on attendance at major league baseball games for all 32 MLB teams from the 1970s-2000. We want to answer the following question:\n\n**\"How big is home-field advantage in baseball? Does a team with higher attendance at home games over their season have score more runs over their season?\"**\n\n### Part A\n\nClean up the data a bit by `mutate()`-ing a variable to measure home attendance in millions. This will make it easier to interpret your regression later on.\n\n### Part B\n\nGet the correlation between Runs Scored and Home Attendance.\n\n### Part C\n\nPlot a scatterplot of Runs Scored (`y`) on Home Attendance (`x`). Add a regression line.\n\n### Part D\n\nWe want to estimate a regression of Runs Scored on Home Attendance:\n\n\n$$\n\\text{runs scored}_i = \\beta_0 + \\beta_1 \\, \\text{home attendance}_i + u_i\n$$\n\n\nRun this regression in R.\n\nWhat are $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ for this model? Interpret them in the context of our question.\n\nHint: make sure to save your regression model as an object, and get a summary() of it. This object will be needed later.\n\n### Part E\n\nWrite out the estimated regression equation.\n\n### Part F\n\nMake a regression table of the output using `modelsummary()`.\n\n### Part G\n\nCheck the goodness of fit statistics. What is the $R^2$ and the $SER$ of this model? Interpret them both in the context of our question.\n\n### Part H\n\nNow let's start running some diagnostics of the regression. Make a histogram of the residuals. Do they look roughly normal?\n\nHint: you will need to use the `broom` package's `augment()` command on your saved regression object to add containing the residuals (`.resid`), and save this as a new object - to be your data source for the plot in this part and the next part.\n\n### Part I\n\nMake a residual plot.\n\n### Part J\n\nTest the regression for heteroskedasticity. Are the errors homoskedastic or heteroskedastic?\n\nHint: use the `lmtest` package's `bptest()` command on your saved regression object.\n\nRun another regression using robust standard errors. Hint: use the `estimatr` package's `lm_robust()` command and save the output like the following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreg_robust <-lm_robust(y ~ x, data = the_data, # change y, x, and data names to yours\n                              se_type = \"stata\") # we'll use this method to calculate\n```\n:::\n\n\nNow make another regression output table with `modelsummary`, with one column using regular standard errors (just use your original saved regression object) and another using robust standard errors (use this new saved object)\n\n### Part K\n\nTest the data for outliers. If there are any, identify which team(s) and season(s) are outliers. Hint: use the `car` package's `outlierTest()` command on your saved regression object.\n\n### Part L\n\nLook back at your regression results. What is the marginal effect of home attendance on runs scored? Is this statistically significant? Why or why not?\n\n### Part M\n\nNow we'll try out the infer package to understand the $p$-value for our observed slope in our regression model.\n\nFirst, save the (value of) our sample $\\hat{\\beta}_1$ from your regression in Part D as an object, I suggest:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nour_slope <- 123 # replace \"123\" with whatever number you found for the slope in part D\n```\n:::\n\n\nThen, using the infer package run the following simulation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# save our simulations as an object (I called it \"sims\")\nsims <- data %>% # \"data\" here is whatever you named your dataframe!\n  specify(y ~ x) %>% # replacing y and x with your variable names\n  hypothesize(null = \"independence\") %>% # H_0 is that slope is 0, x and y are independent\n  generate(reps = 1000,\n           type = \"permute\") %>% # make 1000 samples assuming H_0 is true\n  calculate(stat = \"slope\") # estimate slope in each sample\n\n# look at it\nsims\n\n# calculate p value\nsims %>%\n  get_p_value(obs_stat = our_slope,\n              direction = \"both\") # a two-sided H_a: slope =/= 0\n```\n:::\n\n\nCompare to the p-value in your original regression output in previous parts of this question.\n\n### Part N\n\nMake a histogram of the simulated slopes, and plot our sample slope on that histogram, shading the p-value.\n\nYou can pipe `sims` into `visualize(obs_stat = our_slope)`, or use `ggplot2` to plot a histogram in the normal way, using `sims` as the data source and add a `geom_vline(xintercept = our_slope)` to show our finding on the distribution.",
    "supporting": [
      "03-problem-set_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
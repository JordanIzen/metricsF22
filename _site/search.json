[
  {
    "objectID": "assignments/00-preliminary-survey.html",
    "href": "assignments/00-preliminary-survey.html",
    "title": "Preliminary Survey on Statistics and Software",
    "section": "",
    "text": "This is an ungraded and anonymous survey for me to evaluate the distribution of your math and statistics backgrounds. Please complete all problems to the best of your ability. Your responses will help me craft the course to see which material we need to focus on at greater length, especially review material.\n\n\n Download PDF\n\n\nQuestion 1\nUsing the following sample data:\n\\[8, 12, 9, 10, 11, 5, 15\\]\n\nFind the median.\nCalculate the sample mean, \\(\\bar{x}\\)\nCalculate the sample standard deviation, \\(s\\)\n\n\n\nQuestion 2\nFor a fair, six-sided die:\n\nWhat is the probability of rolling a 5?\nWhat is the probability of rolling an even number?\nWhat is the probability of rolling an even number or a 3?\nIf you have two fair dice, what is the probability of rolling a 6 on both dice?\n\n\n\nQuestion 3\nHedge fund A earns an average rate of return of 2.5% per year with a standard deviation of 0.5%, while hedge fund B earns an average rate of return of 3.0% per year with a standard deviation of 2.0%. Which is more unusual, Hedge fund A earning a 4.0% return or hedge fund B earning a return -1.0% return? Why?1\n\n\nQuestion 4\nA discrete random variable \\(X\\) has the following pdf:\n\n\n\n \n  \n    x \n    p(x) \n  \n \n\n  \n    10 \n    0.1 \n  \n  \n    20 \n    0.2 \n  \n  \n    30 \n    0.3 \n  \n  \n    40 \n    0.4 \n  \n\n\n\n\nCalculate the sample standard deviation, \\(s\\) of \\(X\\).\n\n\nQuestion 5\nThe random variable \\(Y\\) is normally distributed with a mean of 50 and standard deviation of 12\n\\[Y \\sim N (50,12)\\]\n\nWhat is the \\(Z\\)-score for \\(Y=74\\)?\nIn your own words, what does this \\(Z\\)-score mean?\nWhat is the probability that \\(Y\\) takes on a value greater than 74?\n\n\n\nQuestion 6\nOn a scale of 1 (least) to 10 (most), how anxious are you about this class? Feel free to share any specific anxieties (they have a better chance to be specifically addressed if you do!).\n\n\nQuestion 7\nOn a scale of 1 (least) to 10 (most), how familiar would you say you are with computer programming and/or statistical software?\n\n\nQuestion 8\nList any statistical software packages (e.g. R, Microsoft Excel, Stata, SAS, SPSS, Minitab, etc.) and any programming languages (e.g. html, php, C/++, Python, LaTeX, etc.) you have had any experience with, and rate your proficiency between 1 (least) and 5 (most), if applicable.\n\n\n\n\n\nFootnotes\n\n\nHint: Standardize the two hedge funds.↩︎"
  },
  {
    "objectID": "assignments/index.html",
    "href": "assignments/index.html",
    "title": "Assignment Details",
    "section": "",
    "text": "On this page, you can find more information about each individual assignment, as well as the assignments themselves.\nUse this tool to help calculate your overall course grade using existing assignment grades, as well as forecast “what if” scenarios.\nPlease refer to the syllabus for more information about grades."
  },
  {
    "objectID": "assignments/index.html#homeworks",
    "href": "assignments/index.html#homeworks",
    "title": "Assignment Details",
    "section": "Homeworks",
    "text": "Homeworks\nThere will be several problem sets (one at the end of each lesson). Problem sets will be a combination of math/statistical theory & application problems and problems that require use of R with real data. You may collaborate with other students to work on problem sets, but each person must turn in an individual problem set. Problem sets are due one week from the class period where we finish a lesson, and must emailed to me by the start of class (so please type or, if you must, hand write and scan them)."
  },
  {
    "objectID": "assignments/index.html#exams",
    "href": "assignments/index.html#exams",
    "title": "Assignment Details",
    "section": "Exams",
    "text": "Exams\nThis class will have two (2) exams."
  },
  {
    "objectID": "assignments/index.html#midterm-exam",
    "href": "assignments/index.html#midterm-exam",
    "title": "Assignment Details",
    "section": "Midterm Exam",
    "text": "Midterm Exam\nAfter we have finished linear regression, there will be a midterm constituting a combination of multiple choice, problem, and short answer questions. This will cover the content we discuss in class, my lectures, and the readings. The midterm provides feedback both to you and to me that ensures everyone is progressing on schedule and comprehending the material. This is critical, as the rest of the course will build off of this foundation."
  },
  {
    "objectID": "assignments/index.html#final-exam",
    "href": "assignments/index.html#final-exam",
    "title": "Assignment Details",
    "section": "Final Exam",
    "text": "Final Exam\nOn the college-determined date, we will have a comprehensive, closed-book, in-class final exam."
  },
  {
    "objectID": "content/1.1-content.html#overview",
    "href": "content/1.1-content.html#overview",
    "title": "1.1 — Introduction to Econometrics — Class Content",
    "section": " Overview",
    "text": "Overview\nWelcome to ECON 480 — Econometrics! Today’s lesson will be an overview of the content and the assignments of the course. Please read and familiarize yourself with the syllabus.\nThis is not just a “syllabus day,” as we need to hit the ground running, beginning with learning the software we will be using this semester. Starting next class, we will do a deep dive in to R for about 2 weeks. In preparation, please do the following before next class:\n\nGo to RStudio.cloud and register a (free) account with your Hood details.\nTry to install R and R Studio on your computer if you are able, before next class. You will still always have RStudio.cloud available all to use in your browser, but it is much better to have a real version of R and R Studio on your own machine to work with all semester."
  },
  {
    "objectID": "content/1.1-content.html#readings",
    "href": "content/1.1-content.html#readings",
    "title": "1.1 — Introduction to Econometrics — Class Content",
    "section": " Readings",
    "text": "Readings\nToday is introductory, but please heed this timeless message:\n\n\nA message to students from the Doggfather himself, @SnoopDogg pic.twitter.com/wsSANYv8u6\n\n— Ryan Briggs (@ryancbriggs) August 12, 2020\n\n\nPlease note going forward, the lesson numbers and topics (e.g. 1.1) on this website are my design, and will not match up with the textbook!"
  },
  {
    "objectID": "content/1.1-content.html#slides",
    "href": "content/1.1-content.html#slides",
    "title": "1.1 — Introduction to Econometrics — Class Content",
    "section": " Slides",
    "text": "Slides\nBelow, you can find the slides in two formats. Clicking the image will bring you to the html version of the slides in a new tab. Note while in going through the slides, you can type h to see a special list of viewing options, and type o for an outline view of all the slides.\nThe lower button will allow you to download a PDF version of the slides. I suggest printing the slides beforehand and using them to take additional notes in class (not everything is in the slides)!\n\n\n\n\n Download as PDF"
  },
  {
    "objectID": "content/1.1-content.html#assignments",
    "href": "content/1.1-content.html#assignments",
    "title": "1.1 — Introduction to Econometrics — Class Content",
    "section": " Assignments",
    "text": "Assignments\n\nPreliminary Statistics Survey Due By Next Class\nPlease take the preliminary survey on your statistics and software background by nexrt class. This will help us all have a productive semester together."
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Overview",
    "section": "",
    "text": "Please note that the lesson numbers, topics, and titles (e.g. 1.1) are my design, and do not match up with the textbook!"
  },
  {
    "objectID": "credits.html",
    "href": "credits.html",
    "title": "Credits",
    "section": "",
    "text": "This website is written in R Markdown, built with Hugo, pushed to Github, and hosted by Netlify.\nThe theme is based on Academia-hugo, which I modified.\nThe inspiration for making individual course websites, along with the basic structure, comes from the incomparable Andrew Heiss. See his website for examples, as well as a number of helpful tutorials. Sadly, I had to figure out how these websites work on my own, and attempted to document my process in the README of this repository for those interested. One day I may make a guide.\nThe course hex sticker I made via hexSticker, and keep all of my course hex stickers in this repository."
  },
  {
    "objectID": "files/1.1-slides.html#section",
    "href": "files/1.1-slides.html#section",
    "title": "ECON 480 — Econometrics",
    "section": "",
    "text": "1.1 — Introduction to Econometrics\nECON 480 • Econometrics • Fall 2022\nDr. Ryan Safner  Associate Professor of Economics\nsafner@hood.edu  ryansafner/metricsF22  metricsF22.classes.ryansafner.com"
  },
  {
    "objectID": "files/1.1-slides.html#about-me",
    "href": "files/1.1-slides.html#about-me",
    "title": "ECON 480 — Econometrics",
    "section": "About Me",
    "text": "About Me\n\n\n\n\n\nPh.D (Economics) — George Mason University, 2015\nB.A. (Economics) — University of Connecticut, 2011\nSpecializations:\n\nLaw and Economics\nAustrian Economics\n\nResearch interests\n\nmodeling innovation & economic growth\npolitical economy & economic history of intellectual property"
  },
  {
    "objectID": "files/1.1-slides.html#the-reason-im-busy-behind-the-scenes",
    "href": "files/1.1-slides.html#the-reason-im-busy-behind-the-scenes",
    "title": "ECON 480 — Econometrics",
    "section": "The Reason I’m Busy Behind the Scenes",
    "text": "The Reason I’m Busy Behind the Scenes"
  },
  {
    "objectID": "files/1.1-slides.html#why-everyone-yes-everyone-should-learn-statistics",
    "href": "files/1.1-slides.html#why-everyone-yes-everyone-should-learn-statistics",
    "title": "ECON 480 — Econometrics",
    "section": "Why Everyone, Yes Everyone, Should Learn Statistics",
    "text": "Why Everyone, Yes Everyone, Should Learn Statistics\n\n\n SMBC\n\n\n\n\nSMBC"
  },
  {
    "objectID": "files/1.1-slides.html#were-not-so-good-at-statistics-votes-i",
    "href": "files/1.1-slides.html#were-not-so-good-at-statistics-votes-i",
    "title": "ECON 480 — Econometrics",
    "section": "We’re Not So Good at Statistics: Votes I",
    "text": "We’re Not So Good at Statistics: Votes I\n\nVotes in the U.S. House of Representatives in favor of passing the Civil Rights Act of 1964:\n\n\n\n\n\n\nDemocrat\nRepublican\n\n\n\n\n61%\n80%\n\n\n\n\n\nSimple enough: “on average, Republicans tended to vote for passage more than Democrats”"
  },
  {
    "objectID": "files/1.1-slides.html#were-not-so-good-at-statistics-votes",
    "href": "files/1.1-slides.html#were-not-so-good-at-statistics-votes",
    "title": "ECON 480 — Econometrics",
    "section": "We’re Not So Good at Statistics: Votes",
    "text": "We’re Not So Good at Statistics: Votes\n\nVotes in the U.S. House of Representatives in favor of passing the Civil Rights Act of 1964:\n\n\n\n\n\n\n\nDemocrat\nRepublican\n\n\n\n\nNorth\n94%\n85%\n\n\n\n(145/154)\n(138/162)\n\n\nSouth\n7%\n0%\n\n\n\n(7/94)\n(0/10)\n\n\nOverall\n61%\n80%\n\n\n\n(152/248)\n(138/172)\n\n\n\n\n\nLarger proportion of Democrats \\((\\frac{94}{248}\\), 38%) than Republicans \\((\\frac{10}{172}\\), 6%) were from South\nThe 7% of southern Democrats voting for the Act dragged down the Democrats’ overall percentage more than the 0% of southern Republicans"
  },
  {
    "objectID": "files/1.1-slides.html#were-not-so-good-at-statistics-kidney-stones",
    "href": "files/1.1-slides.html#were-not-so-good-at-statistics-kidney-stones",
    "title": "ECON 480 — Econometrics",
    "section": "We’re Not So Good at Statistics: Kidney Stones",
    "text": "We’re Not So Good at Statistics: Kidney Stones\n\n\n\nSuppose you suffer from kidney stones, your doctor offers you treatment A or treatment B\nIn clinical trials, Treatment A was effective for a higher percentage of patients with large stones and a higher percentage of patients with small stones\nTreatment B was effective for a larger percentage of patients overall than treatment A\nWait, what?"
  },
  {
    "objectID": "files/1.1-slides.html#were-not-so-good-at-statistics-kidney-stones-1",
    "href": "files/1.1-slides.html#were-not-so-good-at-statistics-kidney-stones-1",
    "title": "ECON 480 — Econometrics",
    "section": "We’re Not So Good at Statistics: Kidney Stones",
    "text": "We’re Not So Good at Statistics: Kidney Stones\n\n\nFrom a real medical study:\n\n\n\n\nTreatment A\nTreatment B\n\n\n\n\nSmall Stones\n93%\n87%\n\n\n\n(81/87)\n(234/270)\n\n\nLarge Stones\n73%\n69%\n\n\n\n(192/263)\n(55/80)\n\n\nOverall\n78%\n83%\n\n\n\n(273/350)\n(289/350)\n\n\n\nC R Charig, D R Webb, S R Payne, and J E Wickham, 1986, “Comparison of treatment of renal calculi by open surgery, percutaneous nephrolithotomy, and extracorporeal shockwave lithotripsy,” Br Med J (Clin Res Ed) 292(6524): 879–882.\n\n\nThe sizes of the two groups (i.e. who gets A vs B) are very different"
  },
  {
    "objectID": "files/1.1-slides.html#were-not-so-good-at-statistics-kidney-stones-2",
    "href": "files/1.1-slides.html#were-not-so-good-at-statistics-kidney-stones-2",
    "title": "ECON 480 — Econometrics",
    "section": "We’re Not So Good at Statistics: Kidney Stones",
    "text": "We’re Not So Good at Statistics: Kidney Stones\n\n\n\n\n\n\n\n\n\nThe sizes of the two groups (i.e. who gets A vs B) are very different\nA lurking variable in the study is the severity of the case: doctors tended to give treatment B for less severe cases"
  },
  {
    "objectID": "files/1.1-slides.html#simpsons-paradox",
    "href": "files/1.1-slides.html#simpsons-paradox",
    "title": "ECON 480 — Econometrics",
    "section": "Simpson’s Paradox",
    "text": "Simpson’s Paradox\n\n\n\n\n\n\n\n\n\n\n\nSimpson’s Paradox: The correlation between two variables can change (even reverse!) when additional variables are considered]"
  },
  {
    "objectID": "files/1.1-slides.html#were-not-so-good-at-statistics-smoking",
    "href": "files/1.1-slides.html#were-not-so-good-at-statistics-smoking",
    "title": "ECON 480 — Econometrics",
    "section": "We’re Not so Good at Statistics: Smoking",
    "text": "We’re Not so Good at Statistics: Smoking\n\n\n\n1964: U.S. Surgeon General issued a report claiming that cigarette smoking causes lung cancer\nEvidence based primarily on correlations between cigarette smoking and lung cancer"
  },
  {
    "objectID": "files/1.1-slides.html#were-not-so-good-at-statistics-smoking-1",
    "href": "files/1.1-slides.html#were-not-so-good-at-statistics-smoking-1",
    "title": "ECON 480 — Econometrics",
    "section": "We’re Not so Good at Statistics: Smoking",
    "text": "We’re Not so Good at Statistics: Smoking\n\n\n\nTobacco companies attacked the report, naturally"
  },
  {
    "objectID": "files/1.1-slides.html#were-not-so-good-at-statistics-smoking-2",
    "href": "files/1.1-slides.html#were-not-so-good-at-statistics-smoking-2",
    "title": "ECON 480 — Econometrics",
    "section": "We’re Not so Good at Statistics: Smoking",
    "text": "We’re Not so Good at Statistics: Smoking\n\n\n\nRonald A. Fisher\n1890—1924\n\n\nBut so did R. A. Fisher, the “father of modern statistics”"
  },
  {
    "objectID": "files/1.1-slides.html#were-not-so-good-at-statistics-smoking-3",
    "href": "files/1.1-slides.html#were-not-so-good-at-statistics-smoking-3",
    "title": "ECON 480 — Econometrics",
    "section": "We’re Not so Good at Statistics: Smoking",
    "text": "We’re Not so Good at Statistics: Smoking\n\n\n\nThere could be a confounding variable (“smoking gene”) that causes both lung cancer and the urge to smoke\nWould imply: decision to smoke or not would have no impact on lung cancer!\nCorrelation between smoking and cancer is spurious!"
  },
  {
    "objectID": "files/1.1-slides.html#correlation-does-not-imply-causation",
    "href": "files/1.1-slides.html#correlation-does-not-imply-causation",
    "title": "ECON 480 — Econometrics",
    "section": "Correlation Does Not Imply Causation",
    "text": "Correlation Does Not Imply Causation\n\nThe goal of every intro statistics class ever\n\n\nXKCD: Correlation"
  },
  {
    "objectID": "files/1.1-slides.html#correlation-does-not-imply-causation-1",
    "href": "files/1.1-slides.html#correlation-does-not-imply-causation-1",
    "title": "ECON 480 — Econometrics",
    "section": "Correlation Does Not Imply Causation",
    "text": "Correlation Does Not Imply Causation\n\nSpurious Correlations"
  },
  {
    "objectID": "files/1.1-slides.html#correlation-does-not-imply-causation-2",
    "href": "files/1.1-slides.html#correlation-does-not-imply-causation-2",
    "title": "ECON 480 — Econometrics",
    "section": "Correlation Does Not Imply Causation…",
    "text": "Correlation Does Not Imply Causation…\n\n\n\nIt’s always good to be skeptical of causal claims\nBut this is actually where econometrics shines"
  },
  {
    "objectID": "files/1.1-slides.html#econometrics",
    "href": "files/1.1-slides.html#econometrics",
    "title": "ECON 480 — Econometrics",
    "section": "Econometrics",
    "text": "Econometrics\n\n\n\nEconometrics is the application of statistical tools to quantify economic relationships in the real world\nUses real data to\n\ntest economic hypotheses\nquantitatively estimate the magnitude of relationships between economic variables\nforecast future events"
  },
  {
    "objectID": "files/1.1-slides.html#econometrics-and-causal-inference",
    "href": "files/1.1-slides.html#econometrics-and-causal-inference",
    "title": "ECON 480 — Econometrics",
    "section": "Econometrics and Causal Inference",
    "text": "Econometrics and Causal Inference\n\n\n\nWhat sets econometrics apart from mere statistics (or uses of statistics in other disciplines) is its role in causal inference\nWe can, with proper tools and interprations, make quantitative causal claims\n\nabout the effects of individual choices\nabout the effects of policy interventions\nabout the impact of political institutions\nabout economic history and economic development\netc…"
  },
  {
    "objectID": "files/1.1-slides.html#causal-inference-examples",
    "href": "files/1.1-slides.html#causal-inference-examples",
    "title": "ECON 480 — Econometrics",
    "section": "Causal Inference: Examples",
    "text": "Causal Inference: Examples\n\n\n\nA 50% increase in police presence in a metropolitan area lowers crime rates by 15%, on average1\n\n\nBeing an incumbent in office raises the probability of re-election by 40-45 percentage points2\n\n\nEuropean cities with at least one printing press in 1500 were at least 29% more likely to become Protestant by 16003\n\n\n\n\n\nKlick, Jonathan and Alexander Tabarrok, 2005, “Using Terror Alert Levels to Estimate the Effect of Police on Crime,” Journal of Law and Economics 48(1): 267-279Lee, David S, 2001, “The Electoral Advantage to Incumbency and Voters’ Valuation of Politicians’ Experience: A Regression Discontinuity Analysis of Elections to the U.S,” NBER Working Paper 8441Rubin, Jared, 2014, “Printing and Protestants: An Empirical Test of the Role of Printing in the Reformation,” Review of Economics and Statistics 96(2): 270-286"
  },
  {
    "objectID": "files/1.1-slides.html#example-1-education",
    "href": "files/1.1-slides.html#example-1-education",
    "title": "ECON 480 — Econometrics",
    "section": "Example 1: Education",
    "text": "Example 1: Education\n\n\n\n\n\nExample\n\n\n\nDoes reducing class sizes improve student performance?\n\n\n\n\n. . .\n\nA policy-relevant tradeoff with a budget constraint\nWhat is the precise effect of class size on performance?\nIs it worth hiring new teachers and building more schools over?"
  },
  {
    "objectID": "files/1.1-slides.html#example-2-discrimination-in-lending",
    "href": "files/1.1-slides.html#example-2-discrimination-in-lending",
    "title": "ECON 480 — Econometrics",
    "section": "Example 2: Discrimination in Lending",
    "text": "Example 2: Discrimination in Lending\n\n\n\n\n\nExample\n\n\n\nIs there racial discrimination in home mortgage lending?\n\n\n\n\n. . .\n\nBoston Fed: 28% of African-Americans are denied mortgages compared to only 9% of White Americans\nIs this due to factors such as credit history, income, or discrimination purely because of race?"
  },
  {
    "objectID": "files/1.1-slides.html#example-3-public-health-and-public-finance",
    "href": "files/1.1-slides.html#example-3-public-health-and-public-finance",
    "title": "ECON 480 — Econometrics",
    "section": "Example 3: Public Health and Public Finance",
    "text": "Example 3: Public Health and Public Finance\n\n\n\n\n\nExample\n\n\n\nHow much do state cigarette taxes reduce smoking rates?\n\n\n\n\n. . .\n\nEcon 101: raise price \\(\\implies\\) lower quantity consumed\nWhat is the price elasticity of demand for smoking?\nHow much tax revenue will this generate?\nProbably: \\(Taxes \\rightarrow Smokers\\)\nMaybe?: \\(Taxes \\leftarrow Smokers\\)"
  },
  {
    "objectID": "files/1.1-slides.html#real-talk-the-math",
    "href": "files/1.1-slides.html#real-talk-the-math",
    "title": "ECON 480 — Econometrics",
    "section": "Real Talk: The Math",
    "text": "Real Talk: The Math"
  },
  {
    "objectID": "files/1.1-slides.html#real-talk-the-math-1",
    "href": "files/1.1-slides.html#real-talk-the-math-1",
    "title": "ECON 480 — Econometrics",
    "section": "Real Talk: The Math",
    "text": "Real Talk: The Math"
  },
  {
    "objectID": "files/1.1-slides.html#real-talk-the-math-2",
    "href": "files/1.1-slides.html#real-talk-the-math-2",
    "title": "ECON 480 — Econometrics",
    "section": "Real Talk: The Math",
    "text": "Real Talk: The Math"
  },
  {
    "objectID": "files/1.1-slides.html#real-talk-difficulty",
    "href": "files/1.1-slides.html#real-talk-difficulty",
    "title": "ECON 480 — Econometrics",
    "section": "Real Talk: Difficulty",
    "text": "Real Talk: Difficulty\n\n\n\nThis will be one of the hardest courses you take at Hood\nThere will be moments where you have no idea WTF is going on (this is normal)\nYes, you can still get an A"
  },
  {
    "objectID": "files/1.1-slides.html#this-class-is",
    "href": "files/1.1-slides.html#this-class-is",
    "title": "ECON 480 — Econometrics",
    "section": "This Class Is",
    "text": "This Class Is\n\n\n\nEconomics: take your preexisting intuition and models for causal inference\nStatistics: add regression and statistical inference\nComputer Programming: using R and R Studio for analyzing and presenting data ]"
  },
  {
    "objectID": "files/1.1-slides.html#this-class-is-1",
    "href": "files/1.1-slides.html#this-class-is-1",
    "title": "ECON 480 — Econometrics",
    "section": "This Class Is",
    "text": "This Class Is\n\n\nOld School Statistics Courses\n\n\\(\\bar{x} = \\frac{1}{n} \\displaystyle\\sum^n_{i=1} x_i\\)\n\\(\\sigma_x = \\displaystyle \\sqrt{\\frac{1}{n} \\sum^n_{i=1} (x_i-\\bar{x})^2}\\)\n\\(r_{xy}= \\displaystyle \\frac{\\displaystyle\\sum^n_{i=1}(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\displaystyle\\sum^n_{i=1}(x_i-\\bar{x})^2\\sum^n_{i=1}(y_i-\\bar{y})^2}}\\)\nUse pre-cleaned “toy” data, if at all\n\n\nHip New “Data Science” Courses\n\nmean(x)\nsd(x)\ncor(x, y)\n\n\nImport, tidy, and manipulate raw data from scratch (like real life!)"
  },
  {
    "objectID": "files/1.1-slides.html#prerequisites",
    "href": "files/1.1-slides.html#prerequisites",
    "title": "ECON 480 — Econometrics",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nOfficially (Courses):\n\nECON 205\nECON 206\nECON 305 or ECON 306\nMATH 112 or ECMG 212\n\n\n\n\nMath Skills:\n\nBasic algebra\nProbability-ish\nStatistics-ish\n\n\n\n\n\nComputer Science Skills:\n\nNone"
  },
  {
    "objectID": "files/1.1-slides.html#what-youll-get-out-of-this-class",
    "href": "files/1.1-slides.html#what-youll-get-out-of-this-class",
    "title": "ECON 480 — Econometrics",
    "section": "What You’ll Get Out of This Class",
    "text": "What You’ll Get Out of This Class\n\n\nBy the end of this semester, you will:\n\nunderstand how to evaluate statistical and empirical claims;\nuse the fundamental models of causal inference and research design;\ngather, analyze, and communicate with real data in R."
  },
  {
    "objectID": "files/1.1-slides.html#this-class-opens-doors",
    "href": "files/1.1-slides.html#this-class-opens-doors",
    "title": "ECON 480 — Econometrics",
    "section": "This Class Opens Doors",
    "text": "This Class Opens Doors"
  },
  {
    "objectID": "files/1.1-slides.html#building-industry-demanded-data-science-skills",
    "href": "files/1.1-slides.html#building-industry-demanded-data-science-skills",
    "title": "ECON 480 — Econometrics",
    "section": "Building Industry-Demanded Data Science Skills",
    "text": "Building Industry-Demanded Data Science Skills\n\n\n\n\nData Scientist (n.): Person who is better at statistics than any software engineer and better at software engineering than any statistician.\n\n— Josh Wills (@josh_wills) May 3, 2012"
  },
  {
    "objectID": "files/1.1-slides.html#building-industry-demanded-data-science-skills-1",
    "href": "files/1.1-slides.html#building-industry-demanded-data-science-skills-1",
    "title": "ECON 480 — Econometrics",
    "section": "Building Industry-Demanded Data Science Skills",
    "text": "Building Industry-Demanded Data Science Skills\n\n\n\nHarvard Business Review\n\n LinkedIn 2018 Emerging Jobs Report"
  },
  {
    "objectID": "files/1.1-slides.html#r-can-be-used-for-data-science",
    "href": "files/1.1-slides.html#r-can-be-used-for-data-science",
    "title": "ECON 480 — Econometrics",
    "section": "R Can Be Used for Data Science",
    "text": "R Can Be Used for Data Science"
  },
  {
    "objectID": "files/1.1-slides.html#but-remember",
    "href": "files/1.1-slides.html#but-remember",
    "title": "ECON 480 — Econometrics",
    "section": "But Remember",
    "text": "But Remember\n\nThis is an economics course, not a data science course\nOther software economists use (STATA, SASS, SPSS, Excel) is not on here!"
  },
  {
    "objectID": "files/1.1-slides.html#two-uses-for-econometrics",
    "href": "files/1.1-slides.html#two-uses-for-econometrics",
    "title": "ECON 480 — Econometrics",
    "section": "Two Uses For Econometrics",
    "text": "Two Uses For Econometrics\n\n\n\\[\\color{orange}{Y}=\\color{teal}{f}(\\color{purple}{X})\\]\n\nCausal inference: how changes in \\(\\color{purple}{X}\\) cause changes in \\(\\color{orange}{Y}\\)\n\n\nCare more about accurately estimating \\(\\color{teal}{f}\\) than getting an accurate \\(\\color{orange}{\\hat{Y}}\\)\nMeasure the causal effect of \\(X \\mapsto Y\\) (e.g., \\(\\hat{\\beta_1})\\)\n\n\nPrediction: predict \\(\\color{orange}{\\hat{Y}}\\) using an estimated \\(\\color{teal}{f}\\)\n\n\nCare more about getting \\(\\color{orange}{\\hat{Y}}\\) as accurate as possible, \\(\\color{teal}{f}\\) is an unknown “black-box”\nForecasting: predict future values of \\(Y\\) (inflation, sales, GDP)\nClassification: predict the category of an outcome (success or failure, cat picture or not cat picture)\nWe care (in this class at least) only about the first"
  },
  {
    "objectID": "files/1.1-slides.html#causal-inference-economists-comparative-advantage",
    "href": "files/1.1-slides.html#causal-inference-economists-comparative-advantage",
    "title": "ECON 480 — Econometrics",
    "section": "Causal Inference — Economists’ Comparative Advantage",
    "text": "Causal Inference — Economists’ Comparative Advantage\n\n\n\nMachine learning and artificial intelligence are “dumb”1\nWith the right models and research designs, we can say “X causes Y” and quantify it!\nEconomists are in a unique position to make causal claims that mere statistics cannot\n\n\n\n\n\nFor more, see my blog post, and Pearl & MacKenzie (2018), The Book of Why"
  },
  {
    "objectID": "files/1.1-slides.html#causal-inference-economists-comparative-advantage-1",
    "href": "files/1.1-slides.html#causal-inference-economists-comparative-advantage-1",
    "title": "ECON 480 — Econometrics",
    "section": "Causal Inference — Economists’ Comparative Advantage",
    "text": "Causal Inference — Economists’ Comparative Advantage\n\n\n Harvard Business Review\n\n“[T]he field of economics has spent decades developing a toolkit aimed at investigating empirical relationships, focusing on techniques to help understand which correlations speak to a causal relationship and which do not. This comes up all the time — does Uber Express Pool grow the full Uber user base, or simply draw in users from other Uber products? Should eBay advertise on Google, or does this simply syphon off people who would have come through organic search anyway? Are African-American Airbnb users rejected on the basis of their race? These are just a few of the countless questions that tech companies are grappling with, investing heavily in understanding the extent of a causal relationship.”"
  },
  {
    "objectID": "files/1.1-slides.html#building-good-workflow-habits",
    "href": "files/1.1-slides.html#building-good-workflow-habits",
    "title": "ECON 480 — Econometrics",
    "section": "Building Good Workflow Habits",
    "text": "Building Good Workflow Habits\n\n\n\nI will show you the tools to make your workflow:\n\nReproducible\nComputer- and Human-Readable (!)\nAutomated\nAll in one program"
  },
  {
    "objectID": "files/1.1-slides.html#for-example",
    "href": "files/1.1-slides.html#for-example",
    "title": "ECON 480 — Econometrics",
    "section": "For Example",
    "text": "For Example\n\nOutputCode\n\n\n\n\n\n\n\n\n\n\nlibrary(gapminder)\n\nggplot(data = gapminder, \n       aes(x = gdpPercap,\n           y = lifeExp,\n           color = continent))+\n  geom_point(alpha=0.3)+\n  geom_smooth(method = \"lm\")+\n    scale_x_log10(breaks=c(1000,10000, 100000),\n                  label=scales::dollar)+\n    labs(x = \"GDP/Capita\",\n         y = \"Life Expectancy (Years)\")+\n  facet_wrap(~continent)+\n  guides(color = F)+\n  theme_light()"
  },
  {
    "objectID": "files/1.1-slides.html#assignments",
    "href": "files/1.1-slides.html#assignments",
    "title": "ECON 480 — Econometrics",
    "section": "Assignments",
    "text": "Assignments\n\n\n\nResearch project:\n\nCome up with a testable research question\nFind data\nAnalyze data\nPresent your results (in writing and verbally)\n\nHWs\nMidterm, Final exam\n\n\n\n\n\n\n \n  \n     \n    Assignment \n    Percent \n  \n \n\n  \n    1 \n    Research Project \n    30% \n  \n  \n    n \n    Homeworks (Average) \n    25% \n  \n  \n    1 \n    Midterm \n    20% \n  \n  \n    1 \n    Final \n    25%"
  },
  {
    "objectID": "files/1.1-slides.html#logistics",
    "href": "files/1.1-slides.html#logistics",
    "title": "ECON 480 — Econometrics",
    "section": "Logistics",
    "text": "Logistics\n\n\n\nOffice hours: M/W 10:00-11:00 AM & by appt\n\nOffice: 110 Rosenstock\n\n Slack channel #c-306-metrics\nRecorded videos in Blackboard Panopto\nAttendance — Kahoot!s\nTeaching Assistant(s): TBD\n\ngrade HWs & hold office hours\n\nSee the resources page for tips for success and more helpful resources"
  },
  {
    "objectID": "files/1.1-slides.html#your-textbooks",
    "href": "files/1.1-slides.html#your-textbooks",
    "title": "ECON 480 — Econometrics",
    "section": "Your Textbooks",
    "text": "Your Textbooks"
  },
  {
    "objectID": "files/1.1-slides.html#and-i-am-here-to-help",
    "href": "files/1.1-slides.html#and-i-am-here-to-help",
    "title": "ECON 480 — Econometrics",
    "section": "And I am Here To Help",
    "text": "And I am Here To Help\n\nDon’t forget to prioritize your mental health\nCome talk to me! It’s not scary!"
  },
  {
    "objectID": "files/1.1-slides.html#tips-for-success-in-this-course",
    "href": "files/1.1-slides.html#tips-for-success-in-this-course",
    "title": "ECON 480 — Econometrics",
    "section": "Tips for Success in This Course",
    "text": "Tips for Success in This Course\n\n\n\nTake notes. On paper. Really.\nWork together on assignments and study together.\nAsk questions, come to office hours. Don’t struggle in silence, you are not alone!\nThe biggest skill you are developing is learning how to learn1\nSee the reference page for more\n\n\n\n\n\nA properly worded Google search will become your secret weapon. Believe me. It’s still mine"
  },
  {
    "objectID": "files/1.1-slides.html#course-website",
    "href": "files/1.1-slides.html#course-website",
    "title": "ECON 480 — Econometrics",
    "section": "Course Website",
    "text": "Course Website\n metricsF21.classes.ryansafner.com"
  },
  {
    "objectID": "files/1.1-slides.html#roadmap-for-the-semester",
    "href": "files/1.1-slides.html#roadmap-for-the-semester",
    "title": "ECON 480 — Econometrics",
    "section": "Roadmap for the Semester",
    "text": "Roadmap for the Semester\n\n\n\n\nECON 480 — Econometrics"
  },
  {
    "objectID": "files/1.2-slides.html#section",
    "href": "files/1.2-slides.html#section",
    "title": "ECON 480 — Econometrics",
    "section": "",
    "text": "1.2 — Meet R\nECON 480 • Econometrics • Fall 2022\nDr. Ryan Safner  Associate Professor of Economics\nsafner@hood.edu  ryansafner/metricsF22  metricsF22.classes.ryansafner.com"
  },
  {
    "objectID": "files/1.2-slides.html#data-science",
    "href": "files/1.2-slides.html#data-science",
    "title": "ECON 480 — Econometrics",
    "section": "Data Science",
    "text": "Data Science\n\n.hi[You go into data analysis with the tools you know, not the tools you need]\nThe next 2-3 weeks are all about giving you the tools you need\n\nAdmittedly, a bit before you know what you need them for\n\nWe will extend them as we learn specific models"
  },
  {
    "objectID": "files/1.2-slides.html#why-not-excel",
    "href": "files/1.2-slides.html#why-not-excel",
    "title": "ECON 480 — Econometrics",
    "section": "Why Not Excel?",
    "text": "Why Not Excel?"
  },
  {
    "objectID": "files/1.2-slides.html#why-not-excel-1",
    "href": "files/1.2-slides.html#why-not-excel-1",
    "title": "ECON 480 — Econometrics",
    "section": "Why Not Excel?",
    "text": "Why Not Excel?"
  },
  {
    "objectID": "files/1.2-slides.html#r",
    "href": "files/1.2-slides.html#r",
    "title": "ECON 480 — Econometrics",
    "section": "R",
    "text": "R\n\n\n\nFree and open source\nA very large community\n\nWritten by statisticians for statistics\nMost packages are written for R first\n\nCan handle virtually any data format\nMakes replication easy\nCan integrate into documents (with R markdown)\nR is a language so it can do everything\n\nA good stepping stone to learning other languages like Python"
  },
  {
    "objectID": "files/1.2-slides.html#excel-or-stata-cant-do-this",
    "href": "files/1.2-slides.html#excel-or-stata-cant-do-this",
    "title": "ECON 480 — Econometrics",
    "section": "Excel (or Stata) Can’t Do This",
    "text": "Excel (or Stata) Can’t Do This\n\nCodeOutput\n\n\n\nggplot(data = gapminder, \n       aes(x = gdpPercap,\n           y = lifeExp,\n           color = continent))+\n  geom_point(alpha=0.3)+\n  geom_smooth(method = \"lm\")+\n    scale_x_log10(breaks=c(1000,10000, 100000),\n                  label=scales::dollar)+\n    labs(x = \"GDP/Capita\",\n         y = \"Life Expectancy (Years)\")+\n  facet_wrap(~continent)+\n  guides(color = F)+\n  theme_light()"
  },
  {
    "objectID": "files/1.2-slides.html#or-this",
    "href": "files/1.2-slides.html#or-this",
    "title": "ECON 480 — Econometrics",
    "section": "Or This",
    "text": "Or This\n\nInputOutput\n\n\nThe average GDP per capita is ` r dollar(mean(gapminder$gdpPercap)) ` with a standard deviation of ` r dollar(sd(gapminder$gdpPercap)) `.\n\n\nThe average GDP per capita is $7,215.33 with a standard deviation of $9,857.45."
  },
  {
    "objectID": "files/1.2-slides.html#or-this-1",
    "href": "files/1.2-slides.html#or-this-1",
    "title": "ECON 480 — Econometrics",
    "section": "Or This",
    "text": "Or This\n\nlibrary(leaflet)\nleaflet() %>%\n  addTiles() %>%\n  addMarkers(lng = -77.420, lat = 39.421,\n             popup = \"Rosenstock Hall, Hood College\")"
  },
  {
    "objectID": "files/1.2-slides.html#r-and-r-studio",
    "href": "files/1.2-slides.html#r-and-r-studio",
    "title": "ECON 480 — Econometrics",
    "section": "R and R Studio",
    "text": "R and R Studio\n\n\n\n.hiR is the programming language that executes commands\nR Studio is an integrated development environment (IDE) that makes your coding life a lot easier\n\nWrite code in scripts\nExecute individual commands or entire scripts\nAuto-complete, highlight syntax\nView data, objects, and plots\nGet help and documentation on commands and functions\nIntegrate code into documents with R Markdown"
  },
  {
    "objectID": "files/1.2-slides.html#r-and-r-studio-1",
    "href": "files/1.2-slides.html#r-and-r-studio-1",
    "title": "ECON 480 — Econometrics",
    "section": "R and R Studio",
    "text": "R and R Studio\n\n\n\nECON 480 — Econometrics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ECON 480 — Econometrics",
    "section": "",
    "text": "Instructor\n\n   Dr. Ryan Safner\n   114 Rosenstock\n   safner@hood.edu\n   ryansafner\n\n\n\nCourse details\n\n   MW\n   Aug 22—Dec 13, 2022\n   11:30 AM—12:55 PM\n   Rosenstock Trading Room\n   Slack\n\n\n\nContacting me\nEmail."
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "resources/R-packages.html",
    "href": "resources/R-packages.html",
    "title": "R Packages Used in this Course",
    "section": "",
    "text": "You can install all of these packages at once with the following command:\n\ninstall.packages(c(\"tidyverse\", \"ggrepel\", \"broom\", \"car\", \"estimatr\", \"lmtest\",\n                   \"huxtable\", \"infer\", \"dagitty\", \"ggdag\", \"modelsummary\", \"fixest\"))\n\n† Indicates package is part of the tidyverse\n\n\n\nName\nType\nDescription/Reason(s) for Use\nClasses Used\n\n\n\n\nggplot2†\nPlotting\nFor nice plots\n[1.3]\n\n\ngganimate\nPlotting\nFor animating plots\n[1.3]\n\n\nhaven†\nData Wrangling\nFor importing nonstandard data files\n[1.4]\n\n\ndplyr†\nData Wrangling\nFor manipulating data (part of tidyverse)\n[1.4]\n\n\nreadr†\nData Wrangling\nFor importing most data files\n[1.4]\n\n\ntidyr†\nData Wrangling\nFor reshaping data (wide and long)\n[1.4]\n\n\nmagrittr†\nData Wrangling\nFor the pipe\n[1.4]\n\n\ntibble†\nData Wrangling\nFor a friendlier data.frame\n[1.4]\n\n\nggrepel\nPlotting\nFor annotating text that doesn’t cover observations\n[1.4]\n\n\nbroom\nModels\nFor tidying regression output\n[2.3]\n\n\ncar\nModels\nFor testing for outliers\n[2.5]\n\n\nestimatr\nModels\nFor calculating heteroskedasticity-robust standard errors\n[2.5]\n\n\nlmtest\nModels\nFor testing for heteroskedasticity\n[2.5]\n\n\nhuxtable\nOutput\nFor making nice regression tables\n[2.5]\n\n\ninfer\nModels\nFor simulation and statistical inference\n[2.6]\n\n\ndagitty\nModels\nFor working with DAGs in R\n[3.2]\n\n\nggdag\nPlotting\nFor plotting DAGs in ggplot\n[3.2]\n\n\nmodelsummary\nOutput\nFor making nice regression tables\n[3.5]\n\n\nfixest\nModels\nFor working with panel data\n[4.1]\n\n\n\n\n\n\n\nFootnotes\n\n\nNote, many of these packages have multiple uses beyond our purposes!↩︎"
  },
  {
    "objectID": "resources/appendices.html",
    "href": "resources/appendices.html",
    "title": "List of Math & R Appendices",
    "section": "",
    "text": "The following list contains links to all appendices spread across the Class Content pages:\n\n\n\nAppendix\nType\nClass\n\n\n\n\nInstalling R and R Studio\nR\n1.2 class\n\n\nR Packages\nR\n1.2 class\n\n\nGetting Help for R\nR\n1.2 class\n\n\nOther Useful Commands to Know\nR\n1.2 class\n\n\nSuggested Style Guide for Coding\nR\n1.2 class\n\n\nThe Summation Operator\nMath/Stats\n2.1 class\n\n\nUseful Properties of Summation Operators\nMath/Stats\n2.1 class\n\n\nUseful Properties for Regression\nMath/Stats\n2.1 class\n\n\nProperties of Expected Value and Variance\nMath/Stats\n2.2 class\n\n\nGraphing Mathematical Functions\nR\n2.2 class\n\n\nBult-in Statistical Functions\nR\n2.2 class\n\n\nGraphing Statistical Functions\nR\n2.2 class\n\n\nVariance, Covariance, and Correlation\nMath/Stats\n2.3 class\n\n\nDeriving the OLS Estimators\nMath/Stats\n2.4 class\n\n\nAlgebraic Properties of OLS Estimators\nMath/Stats\n2.4 class\n\n\nBias in \\(\\hat{\\beta_1}\\)\nMath/Stats\n2.4 class\n\n\nProof of the Unbiasedness of \\(\\hat{\\beta_1}\\)\nMath/Stats\n2.4 class\n\n\nRobust Standard Errors in R\nR\n2.5 class\n\n\nDifferences Between What We Learned in Class and Classical Statistics\nR\n2.6 class\n\n\nT-Test for Difference in Group Means\nMath/Stats\n3.6 class\n\n\nMarginal Effects for Two-Continuous Variable Interactions\nMath/Stats\n3.7 class"
  },
  {
    "objectID": "resources/computing.html",
    "href": "resources/computing.html",
    "title": "A Quick Guide to Using Your Computer",
    "section": "",
    "text": "File Systems\nBack in my day, search was not very good, and so we had to know where all files were located on our computer. We had folders inside of folders, creating a file hierarchy. Today, search is so good that many in gen Z don’t know where files are stored on their computer, or even “what a file is!” Simply type the name of the document you are looking for into search (whether on Google, Siri, Cortana, Finder, etc) and it magically appears from the depths of…somewhere…on your computer or even in the cloud.\nUnfortunately, when computing and coding, computers need precise instructions about what files to work with, meaning you explicitly need to tell them where on your computer you wish to save a file to, or open an existing file. This means you need to specify the path through the hierarchy of folders on your computer.\n\nMac\n\n| Macintosh HD\n  |- Users\n    |- ryansafner\n      |- Applications\n      |- Desktop\n      |- Documents\n      |- Downloads\n      |- Dropbox\n      |- Movies\n      |- Music\n      |- Pictures\n\n\n\nWindows\n\n\n\nDownloading, Saving, and Opening Files\n\n\nCommand Line"
  },
  {
    "objectID": "resources/data.html",
    "href": "resources/data.html",
    "title": "Data Sources and Suggestions",
    "section": "",
    "text": "A near-comprehensive list of all existing data sets built-in to R or R packages1\n\n\n\n\n\nGoogle Database Search\nKaggle\nHarvard Law School: Find a Database\n\n\n\n\nBelow are packages written by and for R users that link up with the API of key data sets for easy use in R. Each link goes to the documentation and description of each package.\nDon’t forget to install3 first and then load it with library().\n\nowidR for importing data from Our World in Data\nwbstats provides access to all the data available on the World Bank API, which is basically everything on their website. The World Bank keeps track of many country-level indicators over time.\ntidycensus gives you access to data from the US Census and the American Community Survey. These are the largest high-quality data sets you’ll find of cross-sectional data on individual people in the US. You’ll need to get a (free) API key from the website (or ask me for mine).\nfredr gets data from the Federal Reserve’s Economic Database (FRED). You’ll need to get a (free) API key from the website (or ask me for mine).\ntidyquant gets data from a number of financial sources (including fredr).\nicpsrdata downloads data from the Inter-university Consortium for Political and Social Research (you’ll need an account and a keycode). ICPSR is a database of datasets from published social science papers for the purposes of reproducibility.\nNHANES uses data from the US National Health and Nutrition Examination Survey.\nipumsr has census data from all around the world, in addition to the US census, American Community Survey, and Current Population Survey. If you’re doing international micro work, look at IPUMS. It’s also the easiest way to get the Current Population Survey (CPS), which is very popular for labor economics. Unfortunately ipumsr won’t get the data from within R; you’ll have to make your own data extract on the IPUMS website and download it. But ipumsr will read that file into R and preserve things like names and labels.\neducation-data-package-r4 is the Urban Institute’s data data on educational institutions in the US, including colleges (in IPEDS) and K-12 schools (in CCD). This package also has data on county-level poverty rates from SAIPE.\npsidR is the Panel Study of Income Dynamics. This study doesn’t just follow people over their lifetimes, it follows their children too, generationally! A great source for studying how things follow families through generations.\natus is th e American Time Use Survey, which is a large cross-sectional data set with information on how people spend their time.\nRilostat uses data from the International Labor Organization. This contains lots of different statistics on labor, like employment, wage gaps, etc., generally aggregated to the national level and changing over time.\ndemocracyData5 is a great “package for accessing and manipulating existing measures of democracy.”\npoliticaldata provides useful functions for obtaining commonly-used data in political analysis and political science, including from sources such as the Comparative Agendas Project (which provides data on politics and policy from 20+ countries), the MIT Election and Data Science Lab, and FiveThirtyEight.\n\nBelow is a list of good data sources depending on the types of topics you might be interested in writing on:6"
  },
  {
    "objectID": "resources/data.html#key-data-sources",
    "href": "resources/data.html#key-data-sources",
    "title": "Data Sources and Suggestions",
    "section": "Key Data Sources",
    "text": "Key Data Sources\n\nCoronavirus Data: John Hopkins CSSE Covid-19 data (definitive), Our World in Data, New York Times Covid data, covdata r package, Tidy Covid data\nOur World in Data\nAmerican Economic Association Data\nIPUMS (Integrated Public Use Microdata Series)\nEconData from UMD\nICPSR (Inter-university Consortium for Political and Social Research)\nNBER’s Public Use Data Archive\nHistorical Macroeconomic Statistics\nUMD’s Interindustry Forecasting\nDB-nomics\nInternet UPC Database\nInternational Trade Data\nOurWorldinData.org (download datasets)\nSciencesPo International Trade Gravity Dataset\nCenter for International Data\nAtlas of Economic Complexity\nU.N. World Development Reports\nObservatory of Economic Complexity\nReddit /r/datasets\nGoogle Cloud Public Datasets\n\nBy Topic\n\nQuality of Government Data has an extremely wide range of data sources pertaining to measures of institutions. The data itself can be found here.\nNational and State Accounts Data: Bureau of Economic Analysis\nLabor Market and Price Data: Bureau of Labor Statistics\nMacroeconomic Data: Federal Reserve Economic Data (FRED), World Development Indicators (World Bank), Penn World Table\nInternational Data: NationMaster.com, Doing Business, CIESIN\nCensus Data: U.S. Census Bureau\nSports Data: Spotrac, Rodney Fort’s Sports Data\nData Clearing House: Stat USA, Fedstats, Statistical Abstract of the United States, Resources for Economists\nPolitical and Social Data: ICPSR, Federal Election Commission, Poole and Rosenthal Roll Call Data (Voting ideology), Archigos Data on Political Leaders, Library of Congress: Thomas (Legislation), Iowa Electronic Markets (Prediction Markets)\nWar and Violence Data: Correlates of War\nState Level Data: Correlates of State Policy\nHealth Data: Centers for Disease Control, CDC Wonder System\nCrime Data: Bureau of Justice Statistics\nEducation Data: National Center for Education Statistics\nEnvironmental Data: EPA\nReligion Data: American Religion Data Archiva (ARDA)\nFinancial Data: Financial Data Finder{Financial Data Finder}\nPhilanthropy Data: The Urban Institute"
  },
  {
    "objectID": "resources/ggplot2.html#fixing-your-scales",
    "href": "resources/ggplot2.html#fixing-your-scales",
    "title": "ggplot2 Extensions",
    "section": "Fixing Your Scales",
    "text": "Fixing Your Scales"
  },
  {
    "objectID": "resources/ggplot2.html#extensions-to-ggplot2",
    "href": "resources/ggplot2.html#extensions-to-ggplot2",
    "title": "ggplot2 Extensions",
    "section": "Extensions to ggplot2",
    "text": "Extensions to ggplot2\nggplot2, being one of the most popular packages, has a lot of user-made extensions that allow you to do lots of neat things with your plots, from plotting networks, Parliaments, dendrograms, and other types of graphs, to formatting and visual tools that help improve your figures.\nFor the following demonstrations, we will use the gapminder data. Let’s start just by making a basic graph and saving it as an object called p. I have decided to map (aes()) each geom_point’s color to continent and size to pop:\n\nlibrary(gapminder)\nlibrary(ggplot2)\n\np<-ggplot(gapminder) +\n  aes(x = gdpPercap,\n      y = lifeExp) +\n  geom_point(aes(size = pop,\n                 color = continent))\np\n\n\n\n\n\nWorking with Scales\nI don’t like the default choices ggplot2 has made for my point sizes for population, or the way it depicts them (in scientific notation) on the legend.\nI will set my own scale by setting the breaks1 manually, according to a vector I define as: c(100000, 1000000, 100000000, 1000000000). So, I will use one point size for populations of 100 thousand, a bigger one for a million, a bigger one for 100 millions, and the biggest for 1 billion.\nI am going to label these (on my legend) as the following vector: c(\"<1 million\",\"1 million\",\"100 million\", \"1 billion\").\nLastly, I don’t think the size of the billion circle is big enough, a billion is a lot of people! So I will set the range of sizes from size 1 point to size 10 point.\nTo do this, I include all of this inside the scale_size command (because I am scaling the size of points):\n\n# let's save this as p2\np2<-p+scale_size(breaks = c(100000, 1000000, 100000000, 1000000000), # cut offs\n             labels=c(\"<1 million\",\"1 million\",\"100 million\", \"1 billion\"), # labels on legend\n             range=c(1,10)) # min & max point size\n\n# let's see what we did\np2\n\n\n\n\nThis is also very hard to see the relationship (because it is nonlinear!). So I will rescale the x_axis logarithmically with base 10:\n\np2+scale_x_log10()\n\n\n\n\nDoing this already gives me a much clearer view of the relationship! But I don’t like the labels, or the breaks it has chosen, so I can customize them again:\n\np2+scale_x_log10(\n    breaks = c(10^3, 10^4, 10^5), # 1,000, 10,000, and 100,000\n    labels = scales::dollar)\n\n\n\n\nThe scales package has a nice command to format labels, in this case I am calling the scales::dollar function to print dollar signs in front of my axes numbers. I could have done it manually instead by setting labels = c(\"$1,000\", \"$10,000\", \"$100,000\")."
  },
  {
    "objectID": "resources/ggplot2.html#subsetting-data",
    "href": "resources/ggplot2.html#subsetting-data",
    "title": "ggplot2 Extensions",
    "section": "Subsetting Data",
    "text": "Subsetting Data\nWe learn more about this in class 1.4 using tidyverse, but let’s only look at one year of data (there’s too much going on in this plot, especially with the large points, some points are covering other points). So let’s only look at the year 2007. I can do this in two ways:\n\nSubset the data, save the subsetted data as an object (I’ll call gap2007), plot with that object as my data:\n\n\nlibrary(tidyverse)\n\n\ngap2007 <- gapminder %>%\n  filter(year == 2007)\n\np2007 <- ggplot(data = gap2007)+\n  aes(x = gdpPercap,\n      y = lifeExp) +\n  geom_point(aes(size = pop,\n                 color = continent))\n\np2007\n\n\n\n\n\nSubset data and pipe it directly into ggplot2’s data argument:\n\n\nlibrary(tidyverse)\n\np2007 <- gapminder %>%\n  filter(year == 2007) %>%\n  ggplot(data = .)+ # . is placeholder\n  aes(x = gdpPercap,\n      y = lifeExp) +\n  geom_point(aes(size = pop,\n                 color = continent))\n\np2007\n\n\n\n\nNow let’s clean up the graph with the same things I did before, hide the legends (set the color and size, my two aesthetic mappings, guides equal to FALSE), add some labels, and change the theme:\n\np3<-p2007+scale_size(breaks = c(100000, 1000000, 100000000, 1000000000), \n             labels=c(\"<1 million\",\"1 million\",\"100 million\", \"1 billion\"), \n             range=c(1,10))+\n  scale_x_log10(\n    breaks = c(10^3, 10^4, 10^5),\n    labels = scales::dollar)+\n  labs(x = \"GDP per Capita (USD)\",\n       y = \"Life Expectancy (years)\")+\n  guides(color = FALSE,\n         size = FALSE)+\n  theme_classic()\n\nWarning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =\n\"none\")` instead.\n\np3"
  },
  {
    "objectID": "resources/ggplot2.html#ggrepel",
    "href": "resources/ggplot2.html#ggrepel",
    "title": "ggplot2 Extensions",
    "section": "ggrepel",
    "text": "ggrepel\nIf I were to try to label some countries, with either geom_text (just word) or geom_label() (text in a box), setting the label aesthetic to country, see what would happen:\n\np3+geom_label(aes(label = country,\n                  color = continent))\n\n\n\n\nThe labels, which are plotted right on top of each point, cover the points!\nSomeone figured out a clever way to let us do both, and it is a package called ggrepel, which allows you to plot labels that are “repelled” away from the point they are labelling in an intelligent way. This is a separate package, which you must first install and then load with library to use it!\n\n# install.packages(\"ggrepel\") # do this only once\nlibrary(ggrepel)\n\np3+geom_text_repel(aes(label = country,\n                        color = continent,\n                       size = pop),\n                    size = 3)\n\nWarning: ggrepel: 69 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\nThis is much better, but for this particular chart, since a lot of observations are close together, it would be unwise to label everything, perhaps only label a subset of important points."
  },
  {
    "objectID": "resources/ggplot2.html#ggflag",
    "href": "resources/ggplot2.html#ggflag",
    "title": "ggplot2 Extensions",
    "section": "ggflag",
    "text": "ggflag\nOne alternative is instead of points, to use some other marking. Someone created the ggflags package to let you plot flags of countries. This creates a new type of geom, called geom_flag, that requires you to map the country aesthetic to a variable in your data with the country name (incidentally, in gapminder that variable is also called country). Let’s try that out instead (and add my same customizations as above)"
  },
  {
    "objectID": "resources/ggplot2.html#plotly",
    "href": "resources/ggplot2.html#plotly",
    "title": "ggplot2 Extensions",
    "section": "plotly",
    "text": "plotly\nWe can also make our plot a bit more interactive (on web only of course!) using the ggplotly package, which allows ggplot2 to interface with a javascript library called plotly.2\n\n# install.packages(\"plotly\") # do this only once\nlibrary(plotly)\n\n\nggplotly(p3)"
  },
  {
    "objectID": "resources/ggplot2.html#better-barplots",
    "href": "resources/ggplot2.html#better-barplots",
    "title": "ggplot2 Extensions",
    "section": "Better barplots",
    "text": "Better barplots\nAnother major type of plot that we may use often is a barplot. Suppose we want to show the GDP per Capita of the top 20 countries in 2007. If I were to plot country on the x axis and gdpPercap on the y axis with geom_col,3 I get the following mess:\n\nggplot(gap2007)+\n  aes(x = country,\n      y = gdpPercap,\n      fill = continent)+\n  geom_col()\n\n\n\n\nSo let’s filter4 arrange our data in descending order by gdpPercap:\n\ngap2007 %>%\n  arrange(desc(gdpPercap))\n\n# A tibble: 142 × 6\n   country          continent  year lifeExp       pop gdpPercap\n   <fct>            <fct>     <int>   <dbl>     <int>     <dbl>\n 1 Norway           Europe     2007    80.2   4627926    49357.\n 2 Kuwait           Asia       2007    77.6   2505559    47307.\n 3 Singapore        Asia       2007    80.0   4553009    47143.\n 4 United States    Americas   2007    78.2 301139947    42952.\n 5 Ireland          Europe     2007    78.9   4109086    40676.\n 6 Hong Kong, China Asia       2007    82.2   6980412    39725.\n 7 Switzerland      Europe     2007    81.7   7554661    37506.\n 8 Netherlands      Europe     2007    79.8  16570613    36798.\n 9 Canada           Americas   2007    80.7  33390141    36319.\n10 Iceland          Europe     2007    81.8    301931    36181.\n# … with 132 more rows\n\n\nWe only want the top 20 observations, so lets slice to extract just rows 1:20. Then we’ll pipe it into our plot:\n\nbar<-gap2007 %>%\n  arrange(desc(gdpPercap)) %>%\n  slice(1:20) %>%\n  ggplot(data = .)+\n  aes(x = country,\n      y = gdpPercap,\n      fill = continent)+\n  geom_col()\nbar\n\n\n\n\nNow that’s closer to what we wanted! But here are a few more tips and tricks to make it better. First, let’s flip the axes to be able to read the countries better, using coord_flip()\n\nbar+coord_flip()\n\n\n\n\nOne other useful thing to know would be how to display the bars in numerical order (from largest gdpPercap to smalleset gdpPercap) so we can get a clear ranking of countries. To do this, we are going to make use of another tidyverse package called forcats (dealing with factors), specifically the function fct_reorder(), which reorders a factor variable (our country) by the values of some other variable (our gdpPercap). We need to do this to our x variable aesthetic:\n\nbar2<-gap2007 %>%\n  arrange(desc(gdpPercap)) %>%\n  slice(1:20) %>%\n  ggplot(data = .)+\n  aes(x = forcats::fct_reorder(country, gdpPercap), #<<\n      y = gdpPercap,\n      fill = continent)+\n  geom_col()+\n  coord_flip()\nbar2\n\n\n\n\nThis is already looking good. Here’s another creative way to depict the same thing in a more visually-striking way. Instead of using geom_bar(), let’s combine geom_flag (to serve as end points) and geom_segment()5 (line segments) to make the following version:"
  },
  {
    "objectID": "resources/index.html",
    "href": "resources/index.html",
    "title": "Resources",
    "section": "",
    "text": "Look here over the course of the semester for resources, links, and tips on how to succeed in the course, how to write well, and other things of interest related to econometrics, data analysis, managing your workflow, and using R."
  },
  {
    "objectID": "resources/installing-r.html",
    "href": "resources/installing-r.html",
    "title": "Installing R and R Studio",
    "section": "",
    "text": "We will do all of our work in this course with the free & open source programming language R. While you can run everything you need directly in the command line using R, it is a lot more convenient to use an integrated development environment (IDE) like R Studio. Think of R as the engine of a car, and R Studio as the dashboard.\nYou will need to install both, but we will ever only open R Studio."
  },
  {
    "objectID": "resources/installing-r.html#installing-r",
    "href": "resources/installing-r.html#installing-r",
    "title": "Installing R and R Studio",
    "section": "Installing R",
    "text": "Installing R\nFirst you will need to download and install R on your computer.\n\nGo to the Comprehensive R Archive Network (CRAN) that maintains R and its official packages at: https://cran.r-project.org\nClick on “Download R for …” your operating system (Mac or Windows)\n\n\nIf you use a Mac, scroll to the first .pkg file listed on the left and download.\nIf you use Windows, click on base (“This what you want to install R for the first time”)\n\n\nInstall the downloaded package like you would any software application on your computer.\n\n\nTypically, open the file from your Downloads folder (or whever you save downloaded files) and follow the prompts to install on your computer.\n\n\nIf you use a Mac, also download and install XQuartz (https://www.xquartz.org/). You do not need to do this on Windows."
  },
  {
    "objectID": "resources/installing-r.html#install-r-studio",
    "href": "resources/installing-r.html#install-r-studio",
    "title": "Installing R and R Studio",
    "section": "Install R Studio",
    "text": "Install R Studio\n\nGo to RStudio.com and download the free desktop version.\nThe website should automatically detect your operating system and give you a large button to click to download the application.\nInstall the downloaded package like you would any software application on your computer."
  },
  {
    "objectID": "resources/installing-r.html#r-studio-cloud",
    "href": "resources/installing-r.html#r-studio-cloud",
    "title": "Installing R and R Studio",
    "section": "R Studio Cloud",
    "text": "R Studio Cloud\nR is free, but sometimes can be difficult to install and configure on your computer. To make things easier, and to ensure everyone has a consistent experience for class, you can (and should) use the free Rstudio.Cloud service initially. This allows you to run R in your browser (i.e. Chrome, Firefox, Safari, etc), meaning you don’t need to worry about installing things on your computer.\nGo to https://rstudio.cloud and create an account (please use your first and last name). I will send you a link via email to join our class workspace.\nR Studio Cloud is convenient, but is not designed to be as fully customizable and extensive as the main desktop version. I would start with the Cloud version if you have trouble with your own computer or computers on campus running R or R Studio. But ultimately, you will want to eventually do everything on your own computer and not the cloud version."
  },
  {
    "objectID": "resources/pdfs.html",
    "href": "resources/pdfs.html",
    "title": "How to Make a PDF",
    "section": "",
    "text": "There are many good apps out there that will allow you to take photos and convert them to PDFs. This is actually a better method than using your computer (described below), since theses apps optimize your photos for PDFs (using your computer to convert will often result in very large PDF file sizes!). Here are a few apps you can use:\n\nScannable 1\nTurboscan \nImage to PDF Converter Free \nPDF Converter Pro \nSimple Scan \n\nPersonally, I use Scannable — primarily because of its association with Evernote, if you wanted a recommendation. But note it does not exist on Android. I also have successfully used Turboscan in the past.\nAdditionally, as Hood students, you all have Onedrive, you can use the app on your phone to scan documents with photos and convert them to PDFs."
  },
  {
    "objectID": "resources/pdfs.html#using-images-sent-to-your-computer",
    "href": "resources/pdfs.html#using-images-sent-to-your-computer",
    "title": "How to Make a PDF",
    "section": "Using Images Sent to Your Computer",
    "text": "Using Images Sent to Your Computer\nMost modern versions of operating system have a built-in tool in the File Viewer (or Finder) menus, after clicking on one or multiple files, to create a PDF from the files.\nSo first take photos on your smartphone of your written work (one photo per page). Please try to frame your photos properly! Put your paper flat on a solid surface (table, desk, the floor, etc). Get the whole page within the borders of the photo, and not too much background. I don’t need to see half of your desk or bed as you are taking the photo! Take a look at it and make sure it is legible.\nNext, get the photos onto your computer (whether by Airdrop, email to yourself, Dropbox, etc.). Finally, depending on your OS, convert the files to a PDF:\n1. On a Windows PC\nOpen the folder where your photos are currently, in the File Explorer. Select all of the photos, and right click, and select Print. In the dialog box that pops up, select Microsoft Print to PDF in the Printer box, and then click Print. This will save it as a .pdf file in that folder. See more information.\n2. On a Mac\nAs I use a Mac, I will show you how Mac OS has a neat feature built into Finder, which allows converting multiple files into a single PDF file as a Quick Action. I have written two pages in a notebook and taken two separate pictures of them, and airdropped them onto my computer.\n\n\n\nHere is the  example PDF.\n3. On Linux\nIf you use Linux, I assume you know your way around a computer well enough to make a PDF! 🤖"
  },
  {
    "objectID": "resources/reporting-regressions.html",
    "href": "resources/reporting-regressions.html",
    "title": "Reporting Regressions",
    "section": "",
    "text": "Running a regression (or multiple regressions) produces a lot of information — estimated OLS coefficients, hypothesis tests, goodness of fit measures, F-tests, the distribution of residuals, etc. The standard Base R output of the lm() object using summary() looks like this:\nThis contains:"
  },
  {
    "objectID": "resources/reporting-regressions.html#broom",
    "href": "resources/reporting-regressions.html#broom",
    "title": "Reporting Regressions",
    "section": "Broom",
    "text": "Broom"
  },
  {
    "objectID": "resources/reporting-regressions.html#huxtable",
    "href": "resources/reporting-regressions.html#huxtable",
    "title": "Reporting Regressions",
    "section": "Huxtable",
    "text": "Huxtable"
  },
  {
    "objectID": "resources/reporting-regressions.html#modelsummary",
    "href": "resources/reporting-regressions.html#modelsummary",
    "title": "Reporting Regressions",
    "section": "Modelsummary",
    "text": "Modelsummary"
  },
  {
    "objectID": "resources/statistics.html",
    "href": "resources/statistics.html",
    "title": "Statistics Resources",
    "section": "",
    "text": "There are a lot of symbols (often greek letters or ligatures on English letters) used in statistics and econometrics. Luckliy, most of them follow some standard patterns, and are consistent across textbooks and research (note there are exceptions!).\n\n\n\n\n\n\n\n\nStyle\nExamples\nMeaning\n\n\n\n\nGreek letters\n\\(\\beta_0, \\beta_1, \\sigma, u\\)\nTrue parameters of population\n\n\nHats\n\\(\\hat{\\beta_0}, \\hat{\\beta_1}, \\hat{\\sigma}, \\hat{u}\\)\nOur statistical estimates of population parameters, from sample data\n\n\nEnglish capital letters\n\\(X_1, X_2, Y\\)\n(Random) variables in our sample data\n\n\nEnglish lowercase letters\n\\(x_{1i}, x_{2i}, y_i\\)\nIndividual observations of variables in our sample data\n\n\nModified capital letters\n\\(\\bar{X}, \\bar{Y}\\)\nStatistics calculated from our sample data (e.g. sample mean)\n\n\nBold capital letters\n\\(X= \\begin{bmatrix} x_1, x_2, \\cdots , x_n \\\\ \\end{bmatrix}\\) \\(\\mathbf{\\beta} = \\begin{bmatrix} \\beta_1, \\beta_2, \\cdots , \\beta_k \\\\ \\end{bmatrix}\\)\nVector or matrix"
  },
  {
    "objectID": "resources/statistics.html#sample-statistics-vs-population-parameters-formulae",
    "href": "resources/statistics.html#sample-statistics-vs-population-parameters-formulae",
    "title": "Statistics Resources",
    "section": "Sample Statistics vs Population Parameters Formulae",
    "text": "Sample Statistics vs Population Parameters Formulae\n\n\n\n\n\n\n\n\n\nSample\nPopulation\n\n\n\n\nPopulation\n\\(n\\)\n\\(N\\)\n\n\nMean\n\\(\\bar{x} = \\frac{1}{n} \\displaystyle\\sum^n_{i=1} x_i\\)\n\\(\\mu = \\frac{1}{N} \\displaystyle\\sum^N_{i=1} x_i\\)\n\n\nVariance\n\\(s^2=\\frac{1}{n-1} \\displaystyle\\sum^n_{i=1} (x_i-\\bar{x})^2\\)\n\\(\\sigma^2=\\frac{1}{N} \\displaystyle\\sum^N_{i=1} (x_i-\\mu)^2\\)\n\n\nStandard Deviation\n\\(s = \\sqrt{s^2}\\)\n\\(\\sigma = \\sqrt{\\sigma^2}\\)"
  },
  {
    "objectID": "resources/tips.html",
    "href": "resources/tips.html",
    "title": "Tips for Success in This Course",
    "section": "",
    "text": "Footnotes\n\n\nYes, that means I am doing a ton of learning every time I teach!↩︎\nYes, Google is your best friend. But you do not yet know how to ask the right questions, or understand what constitutes good answers.↩︎"
  },
  {
    "objectID": "resources/unzipping_files.html",
    "href": "resources/unzipping_files.html",
    "title": "Unzipping Files",
    "section": "",
    "text": "Since R projects typically consist of multiple files (R scripts, datasets, images, etc.) the easiest way to distribute and send them is to combine all the different files in to a single compressed .zip file. When you unzip a .zip file, your computer extracts all the files contained inside to a new folder on your computer.\nUnzipping files on macOS is simple, but unzipping files on Windows can cause problems if you don’t pay careful attention."
  },
  {
    "objectID": "resources/unzipping_files.html#unzipping-files-on-macos",
    "href": "resources/unzipping_files.html#unzipping-files-on-macos",
    "title": "Unzipping Files",
    "section": "Unzipping files on macOS",
    "text": "Unzipping files on macOS\nDouble click on the downloaded .zip file. macOS will automatically create a new folder with the same name as the .zip file, and all the file’s contents will be inside. Double click on the RStudio Project file (.Rproj) to get started."
  },
  {
    "objectID": "resources/unzipping_files.html#unzipping-files-on-windows",
    "href": "resources/unzipping_files.html#unzipping-files-on-windows",
    "title": "Unzipping Files",
    "section": "Unzipping files on Windows",
    "text": "Unzipping files on Windows\nA long story short: right click on the .zip file, select “Extract All…”, and work with the resulting unzipped folder.\nUnlike macOS, Windows does not automatically unzip things for you. If you double click on the .zip file, Windows will show you what’s inside, but it will do so without actually extracting anything. This is quite annoying. Here’s what it looks like—the only clues that this folder is really a .zip file are that there’s a “Compressed Folder Tools” tab at the top with “Extract” in red.\n\nIt is tempting to just open files from this view, but this causes problems. If you open the R Project file, for instance, RStudio will point to a bizarre working directory buried deep in some temporary folder:\n\nInstead, you need to right click on the .zip file and select “Extract All…”:\n\nThen choose where you want to unzip all the files and click on “Extract”\n\nYou should then finally have a real folder with all the contents of the zipped file. Open the R Project file and RStudio will point to the correct working directory and everything will work."
  },
  {
    "objectID": "resources/wrangling.html",
    "href": "resources/wrangling.html",
    "title": "Advanced Data Wrangling Tips & Tricks",
    "section": "",
    "text": "The majority of data wrangling tasks are described in class 1.4. However, depending on the project, there are particular issues that tend to crop up (often depending on the data type and the state of the spreadsheet) that are worth giving you some help with:"
  },
  {
    "objectID": "resources/wrangling.html#importing-data",
    "href": "resources/wrangling.html#importing-data",
    "title": "Advanced Data Wrangling Tips & Tricks",
    "section": "Importing Data",
    "text": "Importing Data\n\nFrom Google Sheets\n\n\nScraping Data from the Web\nThis is a more advanced technique, but in many use cases (and jobs), an essential tool for acquiring relevant data. There are a number of packages out there, but the one that uses tidyverse principles is rvest.\n\n\nCleaning\nThe janitor package\ncleannames()\n\ngenerally makes lowercase names"
  },
  {
    "objectID": "resources/wrangling.html#dealing-with-missing-data",
    "href": "resources/wrangling.html#dealing-with-missing-data",
    "title": "Advanced Data Wrangling Tips & Tricks",
    "section": "Dealing with Missing Data",
    "text": "Dealing with Missing Data\nWhen calculating statistics (e.g. with summarize()), many calculations will give errors if your data contains NAs.\n\nExample: Calculating Mean\n\ndata_missing <- tribble(\n  ~x, ~y,\n  2, 3,\n  1, 4,\n  NA, 2,\n  3, NA,\n  7, 8\n)\n\nNow if we were to get the mean of x:\n\ndata_missing %>% \n  summarize(mean_x = mean(x))\n\n# A tibble: 1 × 1\n  mean_x\n   <dbl>\n1     NA\n\n\nIt gives us NA.\nOne way to combat this is to ignore all observations that contain NA values. Most statistics functions (like mean()) have an optional argument na.rm, which if set to TRUE, will ignore NAs when performing the calculation:\n\ndata_missing %>%\n  summarize(mean_x = mean(x, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  mean_x\n   <dbl>\n1   3.25"
  },
  {
    "objectID": "resources/wrangling.html#working-with-strings",
    "href": "resources/wrangling.html#working-with-strings",
    "title": "Advanced Data Wrangling Tips & Tricks",
    "section": "Working with Strings",
    "text": "Working with Strings"
  },
  {
    "objectID": "resources/wrangling.html#working-with-dates-time",
    "href": "resources/wrangling.html#working-with-dates-time",
    "title": "Advanced Data Wrangling Tips & Tricks",
    "section": "Working with Dates & Time",
    "text": "Working with Dates & Time"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Content materials contains suggested readings, more details about assignments, math appendices, and other helpful resources. I suggest you view these before each class.\n\n Slides are “Quarto” html presentations that can be opened in any browser (You can find a downloadable PDF on content pages)\n\n\n R materials contain extra tutorials, videos, practice exercises for using R\n\n\n Assignments are listed with due dates\n\n\nPlease note that the lesson numbers, topics, and titles (e.g. 1.1) are my design, and do not match up with the textbook!\nRelevant materials, if applicable will be posted before class meets and become colored links.\n\n\n\n\n\n\n\n\n\n\n\n\n\nI. Data Analysis in R\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nSlides\n\n\nR\n\n\nAssignment\n\n\n\n\n\n\n\n\nPreliminary Survey\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Aug 22\n\n\n1.1 — Introduction to Econometrics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Aug 24\n\n\n1.2 — Meet R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Aug 29\n\n\n1.3 — Data Visualization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Aug 31\n\n\n1.4 — Data Wrangling\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Sep 07\n\n\n1.5 — Optimize Workflow\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem Set 1 Due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nII. Linear Regression\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nSlides\n\n\nR\n\n\nAssignment\n\n\n\n\n\n\nMon Sep 12\n\n\n2.1 — Data and Descriptive Statistics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Sep 14\n\n\n2.2 — Random Variables and Distributions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem Set 2 Due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Sep 19\n\n\n2.3 — OLS Linear Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Sep 21\n\n\n2.4 — OLS: Goodness of Fit and Bias\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Sep 26\n\n\n2.5 — OLS: Precision and Diagnostics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Sep 28\n\n\n2.6 — Statistical Inference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Oct 03\n\n\n2.7 — Inference for Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem Set 3 Due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIII. Causal Inference\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nSlides\n\n\nR\n\n\nAssignment\n\n\n\n\n\n\nWed Oct 05\n\n\n3.1 — The Fundamental Problem of Causal Inference & Potential Outcomes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Oct 10\n\n\n3.2 — Causal Inference & DAGs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Oct 12\n\n\n3.3 — Omitted Variable Bias\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Oct 17\n\n\n3.4 — Multivariate OLS Estimators: Bias, Precision, and Fit\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem Set 4 Due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Oct 19\n\n\n3.5 — Writing an Empirical Paper\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Oct 24\n\n\n3.6 — Regression with Categorical Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Oct 26\n\n\n3.7 — Regression with Interaction Effects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Oct 31\n\n\n3.8 — Polynomial Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Nov 02\n\n\n3.9 — Logarithmic Regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem Set 5 Due\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIV. Panel Data and Advanced Models\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nSlides\n\n\nR\n\n\nAssignment\n\n\n\n\n\n\nMon Nov 07\n\n\n4.1 — Panel Data and Fixed Effects Models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Nov 09\n\n\n4.2 — Difference-in-Difference Models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Nov 14\n\n\nNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Nov 16\n\n\nNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Nov 21\n\n\nNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Nov 23\n\n\nNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Nov 28\n\n\nNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Nov 30\n\n\nNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Dec 05\n\n\nNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWed Dec 07\n\n\nNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMon Dec 12\n\n\nNA"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Dr. Ryan Safner\n   114 Rosenstock\n   safner@hood.edu\n   ryansafner\n   Schedule an appointment\n\n\n\n\n\n   MW\n   Aug 22—Dec 13, 2022\n   11:30 AM—12:55 PM\n   Rosenstock Trading Room\n   Slack\n\n\n\n\nEmail.\nEconometrics is the application of statistical tools to quantify and measure economic relationships in the real world. It uses real data to test economic hypotheses, quantitatively estimate causal relationships between economic variables, and to make forecasts of future events. The primary tool that economists use for empirical analysis is ordinary least squares (OLS) linear regression, so the majority of this course will focus on understanding, applying, and extending OLS regressions.\nI assume you have some working knowledge of economics at the intermediate level and some basic statistical tools.The formal prerequisites for this course are ECON 205 and ECON 206; ECMG 212 or MATH 112; and ECON 305 or ECON 306. We will do some basic review of some necessary statistics and probability at the beginning until everyone is comfortable, before jumping right into regressions."
  },
  {
    "objectID": "syllabus.html#books",
    "href": "syllabus.html#books",
    "title": "Syllabus",
    "section": "Books",
    "text": "Books\nThe following book is required and will be available from the campus bookstore. (You are not obligated to buy it, I just strongly recommend it in the sense that you will still have access to all data and assignments without possessing the book. But this is a course where you really will want to understand the derivations or get additional context beyond just my slides…)\n\nBailey, Michael A, 2019, Real Econometrics, New York: Oxford University Press, 2nd ed.\n\nYou are welcome to purchase the book by other means (e.g. Amazon, half.com, etc). I have no financial stake in requiring you to purchase this book. The (cheaper) 1st edition is sufficient, but makes significantly less use of R (in favor of STATA).\nThe following two books are recommended, and are free online. (You can purchase a hard copy of the first one if you really want.):\n\nGrolemund, Garrett and Hadley Wickham, R For Data Science\nIsmay, Chester and Albert Y Kim, Modern Dive: Statistical Inference Via Data Science\n\nThe first book is the number one resource for using R and tidyverse, and is written for beginners. I still look at it frequently. The second is another great reference for using tidyverse in the context of basic statistics."
  },
  {
    "objectID": "syllabus.html#articles",
    "href": "syllabus.html#articles",
    "title": "Syllabus",
    "section": "Articles",
    "text": "Articles\nThroughout the course, I will post both required and supplemental (non-required) readings that enrich your understanding for each topic."
  },
  {
    "objectID": "syllabus.html#software",
    "href": "syllabus.html#software",
    "title": "Syllabus",
    "section": "Software",
    "text": "Software\nYou are strongly recommended to download copies of R and R Studio on your own computers. These software packages are available on all computers in the trading room, and you will have access to them during the week to work on assignments.\nWe will also have a shared class workspace in RStudio.cloud that runs a full instance of R Studio in your web browser (so no need to install anything!) will let you access files and assignments."
  },
  {
    "objectID": "syllabus.html#attendence",
    "href": "syllabus.html#attendence",
    "title": "Syllabus",
    "section": "Attendence",
    "text": "Attendence\nYour day-to-day classroom attendance is not graded. My philosophy is that you are all adults and must take ownership of your own learning or else you will not succeed. Some assignments may require in-class participation for credit, and an (unexcused) absence may be detrimental to your grade. Attending class is one of the strongest predictors of success.\nHowever, as required under Hood College’s “Promise of Fall Plan,” (Ch. 2-C) your classroom attendance will be recorded at every class meeting. This is primarily to facilitate contact tracing.\nIf you know you will be absent, you are not required to let me know, but it is polite to give notice (Note if I do not reply to an email of yours letting me know, I am probably busy but will still see it and appreciate your email). Your absence will be noted and recorded for the purposes stated above. If, however, we have an assignment due in class, you must notify me ahead of time in order to make alternate arrangements to still receive credit. Hasty ex-post attempts to notify me will generate little sympathy."
  },
  {
    "objectID": "syllabus.html#late-assignments",
    "href": "syllabus.html#late-assignments",
    "title": "Syllabus",
    "section": "Late Assignments",
    "text": "Late Assignments\nI will accept late assignments, but will subtract a specified amount of points as a penalty. Even if it is the last week of the semester, I encourage you to turn in late work: some points are better than no points!\nHomeworks: If you turn in a homework after it is due but before it is graded or the answer key posted, I generally will not take off any points. However, if you turn in a homework after the answer key is posted, I will automatically deduct 15 points (so the maximum grade you can earn on it is an 80).\nExams: If you know that you will be unable to complete an in-class exam as scheduled for a legitimate reason, please notify me at least one week in advance, and we will schedule a make-up exam date. Failure to do so, including desperate attempts to make arrangements only after the exam will result in a grade of 0 and little sympathy.\nPapers: Starting at the deadline, I will take off 1 point for every hour that your assignment is late.\nI reserve the right to re-weight assignments for students whom I believe are legitimately unable to complete a particular assignment."
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nI will try my best to post grades on Blackboard’s Grading Center and return graded assignments to you within about one week of you turning them in. There will be exceptions. Where applicable, I will post answer keys once I know most homeworks are turned in (see Late Assignments above for penalties). Blackboard’s Grading Center is the place to look for your most up-to-date grades. See also my  Grade Calculator app where you can calculate your overall grade using existing assignment grades and forecast “what if” scenarios."
  },
  {
    "objectID": "syllabus.html#communication-email-slack-and-virtual-office-hours",
    "href": "syllabus.html#communication-email-slack-and-virtual-office-hours",
    "title": "Syllabus",
    "section": "Communication: Email, Slack, and Virtual Office Hours",
    "text": "Communication: Email, Slack, and Virtual Office Hours\nStudents must regularly monitor their Hood email accounts to receive important college information, including messages related to this class. Email through the Blackboard system is my main method of communicating announcements and deadlines regarding your assignments. Please do not reply to any automated Blackboard emails - I may not recieve it!. My Hood email (safner@hood.edu) is the best means of contacting me. I will do my best to respond within 24 hours. If I do not reply within 48 hours, do not take it personally, and feel free to send a follow up email in the very likely event that I genuinely did not see your original message.\nOur slack channel is available to all students and faculty in Economics and Business. I have invited all of my classes and advisees. It will not be extended to non-Business/Economics students or faculty. All users must use their hood emails and true first and last names. Each course has its own channel, exclusive for verified students in the course, and myself, by my invite only. As a third party platform, you agree to its Terms of Service. I have created this space as a way to stay connected, to help one another, and to foster community. Behaviors such as posting inappropriate content, harassing others, or engaging in academic dishonesty, to be determined solely at my discretion, will result in one warning, the content will be deleted, and subsequent behavior will result in a ban.\nIn addition to in-person office hours, you can also make an appointment for “office hours” on Zoom. You can join in with video, audio, and/or chat, whichever you feel comfortable with. Of course, if you are not available during those times, we can schedule our own time if you prefer this method over email or Slack. If you want to go over material from class, please have specific questions you want help with. I am not in the business of giving private lectures (particularly if you missed class without a valid excuse).\nWatch this excellent and accurate video explaining office hours:"
  },
  {
    "objectID": "syllabus.html#netiquette",
    "href": "syllabus.html#netiquette",
    "title": "Syllabus",
    "section": "Netiquette",
    "text": "Netiquette\nWhen using Zoom and Slack, please follow appropriate internet etiquette (“Netiquette”). Written communications, like blog posts or use of the Zoom chat, lacks important nonverbal cues (such as body language, tone of voice, sarcasm, etc).\nAbove all else, please respect one another and think/reread carefully about how others may see your post before you submit a comment. You are expected to disagree and have different opinions, this is inherently valuable in a discussion. Please be civil and constructive in responding to others’ comments: writing “have you considered ‘X’?” is a lot more helpful to all involved than just writing “well you’re just wrong.”\nPosting content that is wilfully incindiary, illegal, or that constitutes academic dishonesty (such as plagarism) will automatically earn a grade of 0 and may be elevated to other authorities on campus.\nWhen using the chat function on Zoom or public Slack channels, please treat it as official course communications, even though I may not be grading it. It may be a quick and informal tool - don’t feel you need to worry about spelling or perfect grammar - but please try to avoid too informal “text-speak” (i.e. say “That’s good for you” instead of “thas good 4 u”)."
  },
  {
    "objectID": "syllabus.html#privacy",
    "href": "syllabus.html#privacy",
    "title": "Syllabus",
    "section": "Privacy",
    "text": "Privacy\nMaryland law requires all parties consent for a conversation or meeting to be recorded. If you join in, and certainly if you participate, you are consenting to be recorded. However, as described below, videos are not accessible beyond our class.\nLive lectures are recorded on Zoom and posted to Blackboard via Panopto, a secure course management system for video. Among other nice features (such as multiple video screens, close captioning, and time-stamped search functions!), Panopto is authenticated via your Blackboard credentials, ensuring that our course videos are not accessible to the open internet.\n\nFor the privacy of your peers, and to foster an environment of trust and academic freedom to explore ideas, do not record our course lectures or discussions. You are already getting my official copies.\nThe Family Educational Rights and Privacy Act prevents me from disclosing or discussing any student information, including grades and records about student performance. If the student is at least 18 years of age, parents (or spouses) do not have a right to obtain this information, except with consent by the student.\nMany of you may be tuning in remotely, living with parents, and may have occasional interruptions due to sharing a space. This is normal and fine, but know that I will protect your privacy and not discuss your performance when parents (or anyone other than you, for that matter) are present, without your explicit consent."
  },
  {
    "objectID": "syllabus.html#enrollment",
    "href": "syllabus.html#enrollment",
    "title": "Syllabus",
    "section": "Enrollment",
    "text": "Enrollment\nStudents are responsible for verifying their enrollment in this class. The last day to add or drop this class with no penalty is Wednesday, September 1. Be aware of important dates."
  },
  {
    "objectID": "syllabus.html#honor-code",
    "href": "syllabus.html#honor-code",
    "title": "Syllabus",
    "section": "Honor Code",
    "text": "Honor Code\nHood College has an Academic Honor Code which requires all members of this community to maintain the highest standards of academic honesty and integrity. Cheating, plagiarism, lying, and stealing are all prohibited. All violations of the Honor Code are taken seriously, will be reported to appropriate authority, and may result in severe penalties, including expulsion from the college. See here for more detailed information."
  },
  {
    "objectID": "syllabus.html#van-halen-and-mms",
    "href": "syllabus.html#van-halen-and-mms",
    "title": "Syllabus",
    "section": "Van Halen and M&Ms",
    "text": "Van Halen and M&Ms\nWhen you have completed reading the syllabus, email me a picture of the band Van Halen and a picture of a bowl of M&Ms. If you do this before the date of the first exam, you will get bonus points on the exam. If 75-100% of the class does this, you each get 2 points. If 50-75% of the class does this, you each get 4 points. If 25-50% of the class does this, you each get 6 points. If 0-25% of the class does this, you each get 8 points. Yes, you read this correctly."
  },
  {
    "objectID": "syllabus.html#accessibility-equity-and-accommodations",
    "href": "syllabus.html#accessibility-equity-and-accommodations",
    "title": "Syllabus",
    "section": "Accessibility, Equity, and Accommodations",
    "text": "Accessibility, Equity, and Accommodations\nCollege courses can, and should, be challenging and bring you out of your comfort zone in a safe and equitable environment. If, however, you feel at any point in the semester that certain assignments or aspects of the course will be disproportionately uncomfortable or burdensome for you due to any factor beyond your control, please come see me or email me. I am a very understanding person and am happy to work out a solution together. I reserve the right to modify and reweight assignments at my sole discretion for students that I belive would legitimately be at a disadvantage, through no fault of their own, to complete them as described.\nIf you are unable to afford required textbooks or other resources for any reason, come see me and we can find a solution that works for you.\nThis course is intended to be accessible for all students, including those with mental, physical, or cognitive disabilities, illness, injuries, impairments, or any other condition that tends to negatively affect one’s equal access to education. If at any point in the term, you find yourself not able to fully access the space, content, and experience of this course, you are welcome to contact me to discuss your specific needs. I also encourage you to contact the Office of Accessibility Services (301-696-3421). If you have a diagnosis or history of accommodations in high school or previous postsecondary institutions, Accessibility Services can help you document your needs and create an accommodation plan. By making a plan through Accessibility Services, you can ensure appropriate accommodations without disclosing your condition or diagnosis to course instructors."
  }
]
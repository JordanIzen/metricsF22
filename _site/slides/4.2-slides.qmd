---
format:
  revealjs:
    theme: [default, custom.scss]
    logo: "../images/metrics_hex.png"
    footer: "[ECON 480 — Econometrics](https://metricsF22.classes.ryansafner.com)"
    height: 900
    width: 1600
    df-print: paged
    slide-number: c
    chalkboard: true
overview: true
execute:
  echo: false
  warning: false
  freeze: auto
---

##  {data-menu-title="Title Slide" background-image="images/metrics_title_slide.png"}

[4.2 --- Writing an Empirical Paper]{.custom-title}

[ECON 480 • Econometrics • Fall 2022]{.custom-subtitle}

[Dr. Ryan Safner <br> Associate Professor of Economics]{.custom-author}

[<a href="mailto:safner@hood.edu"><i class="fa fa-paper-plane fa-fw"></i>safner\@hood.edu</a> <br> <a href="https://github.com/ryansafner/metricsF22"><i class="fa fa-github fa-fw"></i>ryansafner/metricsF22</a><br> <a href="https://metricsF22.classes.ryansafner.com"> <i class="fa fa-globe fa-fw"></i>metricsF22.classes.ryansafner.com</a><br>]{.custom-institution}

```{r}
#| label: setup
#| include: false
library(tidyverse)
library(broom)
library(haven)
library(kableExtra)
library(patchwork)
library(fontawesome)
library(gapminder)
library(ggthemes)
library(scales)
library(infer)
library(ggdag)
library(dagitty)
knitr::opts_chunk$set(echo=F,
                      message=F,
                      warning=F)
update_geom_defaults("label", list(family = "Fira Sans Condensed"))
update_geom_defaults("text", list(family = "Fira Sans Condensed"))
```

## Contents {background-color="#314f4f"}

[Structure of an Empirical Paper](#structure-of-an-empirical-paper)

[Some Examples](#some-examples)


## Research Question

- A good paper has a _specific_ [research question]{.hi} that you will ask and provide evidence towards a *clear*, *quantifiable* answer. Good research questions are:

. . .

1. **A claim** about something
	- [Capital punishment is the most efficient deterrent for violent crimes.]{.green}
	- [Women are paid, on average, 33% less than men performing the same work.]{.green}

. . .

2. *As specific as possible**, given the length constraints
  - [Do candidates that spend more money than their opponents tend to win Congressional races?]{.green}

. . .

3. **Testable**, with data that can provide *some* evidence one way or another
  - One study will never be “the” *definitive proof* of something, only *suggestive* evidence

# Structure of an Empirical Paper {.centered background-color="#314f4f"}

## Structure of an Empirical Paper

1. Introduction

2. Literature Review

3. Theory/Model

4. Data Description

5. Empirical Model

6. Results/Implications

7. Bibliography

## Introduction I

- Get to your research question ASAP!  Make it the first sentence even.

- Hook your reader
    - Who cares?  Why is this important?  Why is this relevant? How does this affect people?
		- Statistics and background information can often help

. . .

::: callout-tip
## Example
As a student writing an empirical research paper, does writing a longer paper earn a higher grade on the assignment?
:::

## Introduction II

- State your research question clearly and quickly

. . .

- [Do NOT write a “blog post”]{.red} about how you became interested in the question, or all the work (and dead-ends) that led you on the journey to reaching your final answer
  - [Nobody cares about the labor pains, they just want to see the baby!]{.hi-purple}

. . .

- Provide an outline of the rest of the paper:
  - Why your question matters
  - How you answer the question in this paper
  - What your identification strategy is and what models you use
  - What data you use
  - What your most important results are

## Introduction III

::: callout-tip
## Example
I estimate the relationship between paper length and grades by using a simple OLS regression using sample data collected from previous classes. I find that there is a weak positive effect, that students who write longer papers earn higher grades. On average, for every additional page written, grades improve by less than a point. These results are robust to a number of different model specifications and controls.
:::

## Introduction IV

- Most people do not write enough in their introductions

- Consider the incentives of a (skimming) reader pressed for time
    - If someone only skims your intro, what do you want them to know??
  
- My rough suggestion: make your introduction about 15-20% of your paper:

| Paper Length | Intro Length |
|--------------|--------------|
| 5 pages | 1-1.5 pages |
| 10 pages | 2-2.5 pages |
| 30 pages | 5 pages |

## Literature Review

- **Literature Review** can be summarized into the introduction or given its' own section (debatable)

- [No work is totally original. It's okay!]{.hi-turquoise}
  - What have other relevant researchers written and discovered about your topic?
  - What data and models did they use? What did they find?
  - How does your paper connect and stand apart from what's been done?
    - Does your paper use different data? A different model? Different controls?

## Theory I
 
- This is an *economics* course, so you must describe some [economic theory]{.hi} behind the question you are asking and answering

- Most scholarly papers have a formal economic model, which then generates predictions that they test for with data

- **You do not need a theoretical model**, but you *do* need to discuss economic principles or concepts that are relevant
  - Often there may be multiple theories that might conflict, or our expectations might not be clear (these are the best papers!)
  - There may be a significant tradeoff between competing goals, values, or expectations

## Theory II

::: callout-tip
## Example
Students that write longer papers likely place higher value on their work and dedicate more resources towards improving its quality, resulting in higher grades. 

However, some students may hope or believe that longer papers automatically lead to higher grades, and thus will merely put extra low quality filler in their paper to inflate the length. These papers turn out to be much worse quality, and these students likely earn *lower* grades as a result.
:::

## Data I

- Describe your data sources
  - Who collected or compiled the data and how? 
      - e.g. government agencies, businesses, nonprofits, social surveys, etc.
  - If *you* collected your own data (unlikely), what was your procedure?

## Data II

- Describe the data itself
  - What are your variables? What—*specifically*, and *in English*—does each measure?
  - How many observations do you have?
  - If you transformed your variables—how and why?
      - e.g. recoded into categories or dummies
      - e.g. took logs or rescaled units

## Data III

- [Show your data!]{.hi} Show us basic summary statistics and any patterns
  - Use your judgment: [we don't want or need to see *everything*]{.hi-purple}
  - What do you think is *interesting* or *important*?
  - Plots $>$ Tables $>$ Words $>$ Nothing

. . .

- Good ideas to *always* have:
  1. A table(s) of all variables used and their description
  2. A table(s) of summary statistics of variables
  3. A table of correlations of key variables (optional)
  3. Plots of (only) *the most important* variables & relationships (histograms, boxplots, scatterplots, etc)

## Data: Variables

::: columns
::: {.column width="50%"}
| Variable | Description |
|----------|-------------|
| Grade    | Grade on paper assignment (0-100) |
| Pages    | Number of pages written |
| Final | Final course grade for student |
| Gender | Gender of student |
| Class | Class in which paper was assigned |
| School | School of class taught |
| Year | Year of class |
| Time | Time of day class met |
| Covid | Course during Covid? |

:::
::: {.column width="50%"}
[I collected data at the individual student level from all paper assignments that I have given over the 2013—2021 period at the 3 colleges I have taught at.]{.hi-green}

:::
:::

## Data Correlations {.smaller}

```{r}
#| label: data
papers <- read_csv("../files/data/paperlengthsregcsv.csv")
source("../files/summaries.R")
```

```{r}
papers_numeric <- papers %>%
  mutate(Sex = as.factor(Sex),
         Sex = recode(Sex, `F` = "Female", M = "Male")) %>%
  mutate(Female = ifelse(Sex=="Female",1,0),
         Morning = ifelse(Time=="Morning",1,0),
         Hood = ifelse(School=="Hood",1,0),
         Econometrics = ifelse(Class=="Econometrics",1,0),
         Covid = ifelse(Covid=="Yes",1,0),
         Remote = ifelse(Remote=="Yes",1,0))

papers_numeric %>%
  select_if(is.numeric) %>%
  cor() %>%
  corrplot::corrplot(., type="upper", 
                     tl.col = 'black',
                     method = "number", # number for showing correlation coefficient
                     order="original")
```

## Data: Summary Statistics of Quantitative Variables

```{r}
summary_table(papers_numeric, Pages, Grade, Final, Year, Female, Morning, Hood, Econometrics, Covid, Remote) %>%
  knitr::kable()
```

## Data: Frequency Tables of Categorical Variables I

::: columns
::: {.column width="25%"}
```{r}
papers %>%
  count(Year) %>%
  knitr::kable()
```

:::
::: {.column width="25%"}
```{r}
papers %>%
  count(Sex) %>%
  knitr::kable()
```

:::
::: {.column width="25%"}
```{r}
papers %>%
  count(Time) %>%
  knitr::kable()
```
:::
::: {.column width="25%"}
```{r}
papers %>%
  count(Class) %>%
  knitr::kable()
```
:::
:::

## Data: Frequency Tables of Categorical Variables II

::: columns
::: {.column width="25%"}
```{r}
papers %>%
  count(School) %>%
  knitr::kable()
```

:::
::: {.column width="25%"}
```{r}
papers %>%
  count(Covid) %>%
  knitr::kable()
```

:::
::: {.column width="25%"}
```{r}
papers %>%
  count(Remote) %>%
  knitr::kable()
```
:::
::: {.column width="25%"}
:::
:::


```{r}
papers <- papers %>%
  mutate(Metrics = ifelse(Class == "Econometrics", "Econometrics", "Other"))
```

## Data: Histogram I

```{r, fig.retina=3, fig.align="center", out.width="50%"}
pages_hist <- ggplot(data = papers)+
  aes(x = Pages)+
  geom_histogram(color="white", fill="#e64173",breaks=seq(0,24,2))+
  scale_x_continuous(breaks=seq(0,24,2),
                     limits = c(0,25),
                     expand = c(0,0))+
  scale_y_continuous(breaks=seq(0,60,10),
                     limits = c(0,60),
                     expand = c(0,0))+
  labs(x = "Number of Pages Written",
       y = "Number of Papers")+
    theme_bw(base_family = "Fira Sans Condensed",
           base_size=16)
pages_hist
```


## Data: Histogram II

```{r, fig.retina=3, fig.align="center", out.width="50%"}
pages_hist+facet_wrap(~Sex)
```

## Data: Histogram III

```{r, fig.retina=3, fig.align="center", out.width="50%"}
pages_hist+facet_wrap(~Metrics)
```

## Data: Scatterplot I

```{r, fig.retina=3, fig.align="center", out.width="90%"}

scatter<-ggplot(data = papers)+
  aes(x = Pages,
      y = Grade)+
  geom_jitter(aes(color = Class))+
  geom_smooth(method="lm", color="black")+
  scale_x_continuous(breaks=seq(0,24,2),
                     limits=c(0,25),
                     expand=c(0,0))+
  scale_y_continuous(breaks=seq(0,100,10),
                     limits=c(0,110),
                     expand=c(0,0))+
  coord_cartesian(clip = "off")+
  labs(x = "Number of Pages Written",
       y = "Paper Grade",
       title = "Pages Written vs. Paper Grade (All Classes)")+
    theme_bw(base_family = "Fira Sans Condensed",
           base_size=16)+
  theme(legend.position = "bottom")+
  coord_cartesian(clip = "off")
scatter
```

## Data: Scatterplot I

```{r, fig.retina=3, fig.align="center", out.width="90%"}

scatter_no0s<- papers %>%
  filter(Grade > 0) %>%
  ggplot()+
  aes(x = Pages,
      y = Grade)+
  geom_jitter(aes(color = Class))+
  geom_smooth(method="lm", color="black")+
  scale_x_continuous(breaks=seq(0,24,2),
                     limits=c(0,25),
                     expand=c(0,0))+
  scale_y_continuous(breaks=seq(0,100,10),
                     limits=c(0,110),
                     expand=c(0,0))+
  labs(x = "Number of Pages Written",
       y = "Paper Grade",
       title = "Pages Written vs. Paper Grade (No 0’s)")+
    theme_bw(base_family = "Fira Sans Condensed",
           base_size=16)+
  theme(legend.position = "bottom")
scatter_no0s
```

## Data: Scatterplot III

```{r, fig.retina=3, fig.align="center", out.width="90%"}
scatter_no0s+
  facet_grid(~Sex)
```

## Data: Scatterplot IV

```{r, fig.retina=3, fig.align="center", out.width="90%"}
scatter_no0s+
  facet_grid(~Metrics)
```

## Data: Scatterplot V

```{r, fig.retina=3, fig.align="center", out.width="50%"}

papers %>%
  filter(Class == "Econometrics") %>%
  ggplot()+
  aes(x = Pages,
      y = Grade)+
  geom_jitter(color = "blue")+
  geom_smooth(method="lm", color="red")+
  scale_x_continuous(breaks=seq(0,24,2),
                     limits=c(0,25),
                     expand=c(0,0))+
  scale_y_continuous(breaks=seq(0,100,10),
                     limits=c(0,110),
                     expand=c(0,0))+
  labs(x = "Number of Pages Written",
       y = "Paper Grade",
       title = "Pages Written vs. Paper Grade (Econometrics Only)")+
    theme_bw(base_family = "Fira Sans Condensed",
           base_size=16)
```

## Empirical Model I

- Describe your empirical model and your **identification strategy** 
    - for most of you, just OLS and trying to include as many controls to remove omitted variable bias
    
- Why did you pick certain variables?

- How do you battle endogeneity?

- Hypothesize your expected size and magnitude of key variables
    - Give some **economic intution** behind what we would expect!

## Empirical Model II

::: columns
::: {.column width="50%"}
- [Grade]{.blue} plausibly caused by length ([pages]{.red}), effort, school (uni), gender, course, topic, covid, and time (of day)

- Time of day probably unrelated to length...can safely ignore (don’t need to control for)

- Don’t have good data on topic

- Can’t *directly* measure for the amount of effort you put in, but I can [proxy]{.hi-purple} for it with the final grade in the course (strongly correlated with effort)

:::
::: {.column width="50%"}
```{r}
library(ggdag)
dagify(Grade~Pages+Time+Topic+Uni+Effort+Gender+Course+Remote+Covid,
       Pages~Gender+Uni+Effort+Topic+Course+Covid+Remote,
       Remote~Covid,
       Effort~Uni+Gender+Covid,
       Topic~Gender+Course,
       exposure="Pages",
       outcome="Grade") %>%
  tidy_dagitty(seed = 20) %>%
  ggdag_status()+theme_dag()+theme(legend.position="none")
```
:::
:::

## Empirical Model II

::: columns
::: {.column width="50%"}
- So I need to control for course, covid, effort (proxied by final grade), gender, remote, (if I had data on it...) topic, and university in order to [identify the causal effect]{.hi-purple} of length on grade

:::
::: {.column width="50%"}
```{r}
library(ggdag)
dagify(Grade~Pages+Time+Topic+Uni+Effort+Gender+Course+Remote+Covid,
       Pages~Gender+Uni+Effort+Topic+Course+Covid+Remote,
       Remote~Covid,
       Effort~Uni+Gender+Covid,
       Topic~Gender+Course,
       exposure="Pages",
       outcome="Grade") %>%
  tidy_dagitty(seed = 20) %>%
  ggdag_adjustment_set()+theme_dag()+theme(legend.position="none")
```
:::
:::

## Empirical Model III

::: callout-tip
## Example

\begin{align*}
\text{Paper Grade}_i=& \, \beta_0+\beta_1\text{Paper Length}_i+\beta_2\text{Course Grade}_i\\
&+\beta_3\text{Gender}_i+\beta_4\text{School}_i+\beta_5\text{Covid}_i\\
&+\beta_6\text{Course}_i+\beta_7\text{Remote}_i+u_i\\ \end{align*}
:::

. . .

- $Length$ is the most important variable we care about

- $Length$ probably endogenous, correlated with those other Grade-determining factors:
  - Why I included these controls!
    
- Likely expect $Length$ to be positive and small

## Empirical Model III

::: callout-tip
## Example

\begin{align*}
\text{Paper Grade}_i=& \, \beta_0+\beta_1\text{Paper Length}_i+\beta_2\text{Course Grade}_i\\
&+\beta_3\text{Gender}_i+\beta_4\text{School}_i+\beta_5\text{Covid}_i\\
&+\beta_6\text{Course}_i+\beta_7\text{Remote}_i+u_i\\ \end{align*}

:::

. . .

- You are probably interested specifically in the relationship only for econometrics papers, so we can focus Course specifically to a binary variable $Metrics$ to see how the results differ between non-econometrics courses

- Alternatively, we can restrict our sample to *only* past econometrics classes

## Empirical Model IV

- Describe the **limitations of your model**
    - Every paper, even Nobel prize-winning ones, have limitations and problems!
    - Limited and/or poor quality data
    - Endogeneity, simultaneous causation, omitted variable bias

::: callout-tip
## Example
The model likely suffers from endogeneity, as how many pages a student writes is likely to be positively correlated with personal attributes like diligence, conscientiousness, and intelligence, which themselves are likely positively correlated with the grade of the paper. Thus, we have likely *over*stated the effect of page length on paper grades. Furthermore, we are unable to measure other variables that make page length endogenous, such as the topic that was chosen. Some topics lend themselves to shorter or longer papers and may have better or worse data that make it easier or difficult to run a clean empirical test.

:::

## Empirical Model V

- Are your results [robust]{.hi} across different model specifications?
  - Do the size(s) of the marginal effect(s) you care about change or reverse direction? Become/lose significance?
    
- At minimum, [you must run several models]{.hi-purple}, including a multivariate regression
  - Run **several variations** of your model with and without controls (e.g. just $Y$ and $X$, $Y$ and $X_1$ and $X_2$, etc.)
  - Check for nonlinearities: polynomials, logs, etc.


## Results I

- Print a table(s) of your regression(s) results (`modelsummary` and other packages can help)

- Interpret your data (in the text of the paper)
  - What does a marginal (1 unit) change in $X$ mean for $Y$, a 1% change, etc? 
  - Is each coefficient statistically significant (at 10%, 5%, or 1% levels)?

```{r}
papers0 <- papers %>%
  filter(Grade>0)

hood <- papers %>%
  filter(School=="Hood")

metrics <- papers %>%
  filter(Class=="Econometrics")

metricsno0s <- papers0 %>%
  filter(Class=="Econometrics")

basicreg <- lm(Grade~Pages, data=papers)
no0reg <- lm(Grade~Pages, data=papers0)
basicmetricsreg <- lm(Grade~Pages, data=metrics)
controlsreg <- lm(Grade~Pages+Final+Sex+School+Metrics+Covid+Remote, data=papers0)
hoodreg <- lm(Grade~Pages+Final+Sex+Metrics+Covid+Remote, data=hood)
metricsreg <- lm(Grade~Pages+Final+Sex+Covid+Remote, data=metrics)
metricsno0sreg <- lm(Grade~Pages+Final+Sex+Covid+Remote, data=metricsno0s)
```

## {.smaller}

```{r}
library(modelsummary)
modelsummary(models = list("Baseline" = basicreg,
                           "No 0s" = no0reg,
                           "Econometrics Only" = basicmetricsreg,
                           "With Controls" = controlsreg,
                           "Hood Only" = hoodreg,
                           "Metrics Only" = metricsreg,
                           "Metrics Only No 0s" = metricsno0sreg),
             fmt = 2, # round to 2 decimals
             output = "html",
             coef_omit = c("(Intercept)"),
             coef_rename = c(#"(Intercept)" = "Constant",
                             "Length" = "Pages",
                             "Final" = "Course Grade",
                             "SexM" = "Male",
                             "SchoolHood" = "Hood",
                             "MetricsOther" = "Non-metrics Course",
                             "CovidYes" = "During Covid",
                             "RemoteYes" = "Taught Remotely"),
             gof_map = list(
               list("raw" = "nobs", "clean" = "N", "fmt" = 0),
               #list("raw" = "r.squared", "clean" = "R<sup>2</sup>", "fmt" = 2),
               list("raw" = "adj.r.squared", "clean" = "Adj. R<sup>2</sup>", "fmt" = 2),
               list("raw" = "rmse", "clean" = "SER", "fmt" = 2)
             ),
             escape = FALSE,
             stars = c('*' = .1, '**' = .05, '***' = 0.01)
)

```

::: footer
:::

## Results II

::: columns
::: {.column width="50%"}
```{r}
controlsreg %>%
  broom::tidy(conf.int = T) %>%
  filter(term != "(Intercept)") %>%
ggplot(data = .)+
  aes(x = estimate,
      y = term,
      color = term)+
    geom_point(size=3)+ # point for estimate
    # now make "error bars" using conf. int.
    geom_segment(aes(x = conf.low,
                     xend = conf.high,
                     y=term,
                     yend=term))+
  # add line at 0
  geom_vline(xintercept=0, size=1, color="black")+
  #scale_x_continuous(breaks=seq(-1.5,0.5,0.5),
  #                   limits=c(-1.5,0.5))+
  labs(x = "Marginal effect (with 95% confidence interval)",
       y = "",
       title = "Coefficient Plot (All Courses & Colleges)")+
  scale_x_continuous(breaks=seq(-2,8,1))+
  guides(color=F)+ # hide legend
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=16)

```
:::
::: {.column width="50%"}
```{r}
metricsreg %>%
  broom::tidy(conf.int = T) %>%
  filter(term != "(Intercept)") %>%
ggplot(data = .)+
  aes(x = estimate,
      y = term,
      color = term)+
    geom_point(size=3)+ # point for estimate
    # now make "error bars" using conf. int.
    geom_segment(aes(x = conf.low,
                     xend = conf.high,
                     y=term,
                     yend=term))+
  # add line at 0
  geom_vline(xintercept=0, size=1, color="black")+
  #scale_x_continuous(breaks=seq(-1.5,0.5,0.5),
  #                   limits=c(-1.5,0.5))+
  labs(x = "Marginal effect (with 95% confidence interval)",
       y = "",
       title = "Coefficient Plot (Econometrics Courses Only)")+
  guides(color=F)+ # hide legend
  theme_bw(base_family = "Fira Sans Condensed",
           base_size=16)
```

:::
:::

## Results: Interpretation! I

- Are your estimates **economically significant**?

- How big is "big"?

> “No economist has achieved scientific success as a result of a statistically significant coefficient. Massed observations, clever common sense, elegant theorems, new policies, sagacious economic reasoning, historical perspective, relevant accounting, these have all led to scientific success. Statistical significance has not.” — McCloskey & Ziliak (1996: 112)


## Results: Interpretation! II

![](images/drwhocontext.jpg){fig-align="center"}


## Results: Interpretation! III

::: callout-tip
## Example

I find that for every additional page written, we can expect a paper's grade to increase by about a point or less, after controlling for other factors such as Final grade (proxying as a measure of overall diligence and intelligence), sex, and course. In the most relevant sample, econometrics students, the marginal effect is even smaller, only less than half of a point increase for every additional page written.

However, we should not make much of these results due to the likely endogeneity of Pages due to unobserved factors such as topic and quality of writing, which clearly would matter much both for length and for grade. *It would be poor advice to recommend students simply to write long papers to earn a higher grade.*
:::


## Results: Implications

- Describe several *implications* of your paper
  - Policy implications
  - Proposals for new research
  - Effects on current understanding
  - What else should we try to found out to answer the question better?


## Don't Get Discouraged I

::: columns
::: {.column width="50%"}
![](images/sciencerage.png){fig-align="center" width=450}
:::
::: {.column width="50%"}

:::
:::

## Don't Get Discouraged I

::: columns
::: {.column width="50%"}
![](images/sciencerage.png){fig-align="center" width=450}
:::
::: {.column width="50%"}
![](images/sciencerage1.png){fig-align="center" width=450}

:::
:::

## Don't Get Discouraged II

::: columns
::: {.column width="30%"}
![](images/einstein.png){fig-align="center" width=500}

Albert Einstein

1870-1924
:::
::: {.column width="70%"}

> "If we knew what it was we were looking for, we wouldn't call it research, would we?"

:::
:::

## Deadlines and Reminders (From the Assignment Page)

| Assignment | Points | Due Date | Description |
|------------|--------|----------|-------------|
| Abstract | 5 | Fri Oct 28 | Short summary of your ideas |
| Literature Review | 10 | Fri Nov 18 | 1-3 paragraphs on 2-3 scholarly sources |
| Data Description | 10 | Mon Nov 28 | Description of data sources, and some summary statistics |
| Presentation | 5 | Nov 30/Dec 5 | Short presentation of your project so far |
| Final Paper Due | 70 | Fri Dec 9 | Email to me paper, data, and code |

## Grading of Final Paper (From the Assignment Page)

| Category | Points |
|----------|--------|
| Persuasiveness | 10 |
| Clarity | 10 |
| Econometric Validity | 20 |
| Economic Soundness | 20 |
| Organization | 5 |
| References | 5 |
| TOTAL | 70 |

## Submitting Your Final Paper

When you send your final email (by Monday December 6), it should contain the following files:

1. **Your final paper as a `.pdf`.** It should include an abstract and bibliography and all tables and figures contained within it. 
2. **The (commented!) code used for your data analysis** (i.e. loading data, making tables, making plots, running regressions). These can be either `.R` files: one or multiple (one-per-task) are equally fine OR a `.qmd` file. I want to know *how* you reached the results you got! **Reproducibility is the goal!**
3. **Your data used**, in whatever original format you found it (e.g. `.csv`, `.xlsx`, `.dta`)

Again, you are not obligated to use `Quarto` to write your paper. Microsoft Word is fine.


# Some Examples {.centered background-color="#314f4f"}

## Example 1

> “Exploring the Effects of Children and Marriage on Men’s and Women’s Incomes”

\begin{align*}
\text{Income}_i = & \, \beta_0+\beta_1 \text{Number of Children}_i\\
&+ \beta_2 \text{Math SAT Score}_i + \beta_3 \text{Sex}_i + \beta_4 \text{Hours Worked per Week}_i\\
&+ \beta_5 \text{Married}_i+u_i\\ \end{align*}

- Cross-sectional data for individual $i$

## Example 2

> “Does Spending More on the Offensive Line & the Defensive Line Affect NFL Team Wins?”

\begin{align*}
\text{Wins}_{ty} = & \, \beta_0+\beta_1 \text{OL & DL Spending}_{ty}\\
&+ \beta_2 \text{Quarterback Spending}_{ty}\\
&+\beta_3 \text{Defensive Coach Spending}_{ty}+\alpha_r+\tau_y+\epsilon_{it}+u_{ty}\\ \end{align*}

- Panel data with two way fixed effects for team $t$ in year $y$; 

## Example 3

> “Buy You a Vote”

\begin{align*}
\text{Vote Share}_{it} = & \, \beta_0+\beta_1 \text{Incumbent}_{it} + \beta_2 \text{Incumbent Spending}_{it}\\
&+ \beta_3 \text{Non-Incumbent Spending}_{it}+\beta_4 \text{Number of Candidates}_{it}\\
&+\beta_5 \text{Political Party}_{it}+\alpha_i+\tau_t+\epsilon_{it}\\ \end{align*}

- Panel data with two way fixed effects for candidate $i$ at time $t$


## Example 4

> “A Cross-Sectional Study on the Effect of State Minimum Wage on Youth Unemployment at the State Level”

\begin{align*}
\text{ln(Unemployment Rate)}_{i} = & \, \beta_0+\beta_1 \text{ln(Minimum Wage)}_{i} + \beta_2 \text{Spending per Student}_{i}\\
&+ \beta_3 \text{Poverty Rate}_{i}+u_i \\ \end{align*}

- Cross-sectional data for U.S. State $i$

## Example 5

> “Is Twitter Strong Enough to Measure NBA Player Performance?”

\begin{align*}
\text{Player Impact Estimate}_{i} = & \, \beta_0+\beta_1 \text{ln(Number of Twitter Followers)}_{i} + \beta_2 \text{Age}_{i}\\
&+ \beta_3 \text{Games Played}_{i}+\beta_4 \text{Minutes played per game}_{i}\\
& +\beta_5 \text{Points scored per game}_{i}+ \beta_6 \text{Salary}_{i}+u_i\\ \end{align*}

- Cross-sectional data for player $i$

## Example 6

> “The Effect of Economic Growth on Carbon Dioxide Emissions”

\begin{align*}
\ln\text{CO}_{2it} = & \, \beta_0+\beta_1 \ln \text{GDP per capita}_{it} + \beta_2 \ln \text{GDP per capita}_{it}^2\\
&+ \beta_3 \text{Urbanization Rate}_{it}+ \alpha_i + \tau_t + u_{it}\\ \end{align*}

- A nonlinear (quadratic) model with panel data and two-way fixed effects for country $i$ in time $t$


